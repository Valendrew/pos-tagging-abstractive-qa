{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1d23b6c",
      "metadata": {
        "id": "d1d23b6c"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Keywords**: Transformers, Question Answering, CoQA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dL4rB4Dv4q5D",
      "metadata": {
        "id": "dL4rB4Dv4q5D"
      },
      "source": [
        "## Task and dataset explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ada8c8",
      "metadata": {
        "id": "11ada8c8"
      },
      "source": [
        "### Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c07553",
      "metadata": {
        "id": "47c07553"
      },
      "source": [
        "### Problem\n",
        "\n",
        "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4907f8d",
      "metadata": {
        "id": "b4907f8d"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
        "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
        "\n",
        "**Note**: an question $Q$ can refer to previous dialogue turns. <br>\n",
        "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3760b5",
      "metadata": {
        "id": "9b3760b5"
      },
      "source": [
        "### Models\n",
        "\n",
        "We are going to experiment with transformer-based models to define the following models:\n",
        "\n",
        "1.  $A = f_\\theta(Q, P)$\n",
        "\n",
        "2. $A = f_\\theta(Q, P, H)$\n",
        "\n",
        "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cfee64",
      "metadata": {
        "id": "66cfee64"
      },
      "source": [
        "### The CoQA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996fa650",
      "metadata": {
        "id": "996fa650"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e3e7d0",
      "metadata": {
        "id": "f6e3e7d0"
      },
      "source": [
        "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb6c37e",
      "metadata": {
        "id": "bfb6c37e"
      },
      "source": [
        "### Rationales\n",
        "\n",
        "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
        "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa786e2",
      "metadata": {
        "id": "daa786e2"
      },
      "source": [
        "### Dataset Statistics\n",
        "\n",
        "* **127k** QA pairs.\n",
        "* **8k** conversations.\n",
        "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
        "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
        "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
        "* Only **train** and **validation** sets are available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26d68b7",
      "metadata": {
        "id": "d26d68b7"
      },
      "source": [
        "### Dataset snippet\n",
        "\n",
        "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"source\": \"mctest\",\n",
        "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
        "    \"filename\": \"mc160.test.41\",\n",
        "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
        "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        {\n",
        "            \"input_text\": \"Where did she live?\",\n",
        "            \"turn_id\": 2\n",
        "        },\n",
        "        [...]\n",
        "    ],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"span_start\": 59,   % <-- $R_1$ start index\n",
        "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
        "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
        "            \"input_text\" \"white\",   % <-- $A_1$      \n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        [...]\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c7558c",
      "metadata": {
        "id": "72c7558c"
      },
      "source": [
        "### Simplifications\n",
        "\n",
        "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
        "\n",
        "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b532042",
      "metadata": {
        "id": "7b532042"
      },
      "source": [
        "## List of tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01cdad7",
      "metadata": {
        "id": "e01cdad7"
      },
      "source": [
        "### [Task 1] Remove unaswerable QA pairs \n",
        "\n",
        "Write your own script to remove unaswerable QA pairs from both train and validation sets. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f57334e0",
      "metadata": {
        "id": "f57334e0"
      },
      "source": [
        "### [Task 2] Train, Validation and Test splits\n",
        "\n",
        "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
        "\n",
        "We'll consider the provided validation set as a test set. <br>\n",
        "$\\rightarrow$ Write your own script to:\n",
        "* Split the train data in train and validation splits (80% train and 20% val)\n",
        "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
        "* Perform splitting using the following seed for reproducibility: 42\n",
        "\n",
        "#### Reproducibility Memo\n",
        "\n",
        "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "230a21de",
      "metadata": {
        "id": "230a21de"
      },
      "source": [
        "### [Task 3] Model definition\n",
        "\n",
        "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
        "\n",
        "* [M1] DistilRoBERTa (distilberta-base)\n",
        "* [M2] BERTTiny (bert-tiny)\n",
        "\n",
        "**Note**: Remember to install the ```transformers``` python package!\n",
        "\n",
        "**Note**: We consider small transformer models for computational reasons!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e83f28",
      "metadata": {
        "id": "f1e83f28"
      },
      "source": [
        "### [Task 4] Question generation with text passage $P$ and question $Q$\n",
        "\n",
        "We want to define $f_\\theta(P, Q)$. \n",
        "\n",
        "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7311ba86",
      "metadata": {
        "id": "7311ba86"
      },
      "source": [
        "### [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
        "\n",
        "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ac768c",
      "metadata": {
        "id": "b5ac768c"
      },
      "source": [
        "### [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
        "\n",
        "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
        "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
        "* Fine-tune each transformer-based models for **3 epochs**.\n",
        "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
        "\n",
        "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
        "\n",
        "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92c7e98f",
      "metadata": {
        "id": "92c7e98f"
      },
      "source": [
        "### [Task 7] Error Analysis\n",
        "\n",
        "Perform a simple and short error analysis as follows:\n",
        "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
        "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
        "\n",
        "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6643e14",
      "metadata": {
        "id": "f6643e14"
      },
      "source": [
        "## Dataset Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6cZJRT4tU1ms",
      "metadata": {
        "id": "6cZJRT4tU1ms"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path\n",
        "import json\n",
        "import typing\n",
        "import urllib.request\n",
        "import random\n",
        "\n",
        "import keras.callbacks\n",
        "import keras.layers\n",
        "import keras.losses\n",
        "import keras.optimizers\n",
        "import keras.regularizers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "358bac70",
      "metadata": {
        "id": "358bac70"
      },
      "outputs": [],
      "source": [
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5f6ab3ff",
      "metadata": {
        "id": "5f6ab3ff"
      },
      "outputs": [],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bddb1b09",
      "metadata": {
        "id": "bddb1b09"
      },
      "source": [
        "## Create the dataframe, inspect the data and do some preprocessing [TASK 1, TASK 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "89e33d91",
      "metadata": {
        "id": "89e33d91"
      },
      "outputs": [],
      "source": [
        "train_path = './coqa/train.json'\n",
        "test_path = './coqa/test.json'\n",
        "\n",
        "with open(train_path, 'r') as f:\n",
        "    train_json = json.load(f)\n",
        "\n",
        "with open(test_path, 'r') as f:\n",
        "    test_json = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JARrWA8lmPO_",
      "metadata": {
        "id": "JARrWA8lmPO_"
      },
      "source": [
        "Given that the dataset is provided as a json file we decided to unpack it with a first rough operation creating a column of a DataFrame for each key of the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a10f052",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9a10f052",
        "outputId": "7775349d-c5f4-47d7-b130-0778d48490ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      source                              id  \\\n",
              "0  wikipedia  3zotghdk5ibi9cex97fepx7jetpso7   \n",
              "1        cnn  3wj1oxy92agboo5nlq4r7bndc3t8a8   \n",
              "2  gutenberg  3bdcf01ogxu7zdn9vlrbf2rqzwplyf   \n",
              "3        cnn  3ewijtffvo7wwchw6rtyaf7mfwte0p   \n",
              "4  gutenberg  3urfvvm165iantk80llvkwwbjs7uzh   \n",
              "\n",
              "                                            filename  \\\n",
              "0                                Vatican_Library.txt   \n",
              "1  cnn_fe05c61a7e48461f7883cdec387567029614f07b.s...   \n",
              "2  data/gutenberg/txt/Zane Grey___Riders of the P...   \n",
              "3  cnn_0c518067e0df811501e46b2e1cd1ce511f1645b7.s...   \n",
              "4  data/gutenberg/txt/Rafael Sabatini___Love-at-A...   \n",
              "\n",
              "                                               story  \\\n",
              "0  The Vatican Apostolic Library (), more commonl...   \n",
              "1  New York (CNN) -- More than 80 Michael Jackson...   \n",
              "2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n",
              "3  (CNN) -- The longest-running holiday special s...   \n",
              "4  CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...   \n",
              "\n",
              "                                           questions  \\\n",
              "0  [{'input_text': 'When was the Vat formally ope...   \n",
              "1  [{'input_text': 'Where was the Auction held?',...   \n",
              "2  [{'input_text': 'What did Venters call Lassite...   \n",
              "3  [{'input_text': 'Who is Rudolph's father?', 't...   \n",
              "4  [{'input_text': 'Who arrived at the church?', ...   \n",
              "\n",
              "                                             answers  \\\n",
              "0  [{'span_start': 151, 'span_end': 179, 'span_te...   \n",
              "1  [{'span_start': 243, 'span_end': 284, 'span_te...   \n",
              "2  [{'span_start': 841, 'span_end': 880, 'span_te...   \n",
              "3  [{'span_start': 500, 'span_end': 557, 'span_te...   \n",
              "4  [{'span_start': 254, 'span_end': 297, 'span_te...   \n",
              "\n",
              "                                                name  \n",
              "0                                Vatican_Library.txt  \n",
              "1  cnn_fe05c61a7e48461f7883cdec387567029614f07b.s...  \n",
              "2  data/gutenberg/txt/Zane Grey___Riders of the P...  \n",
              "3  cnn_0c518067e0df811501e46b2e1cd1ce511f1645b7.s...  \n",
              "4  data/gutenberg/txt/Rafael Sabatini___Love-at-A...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8288b47d-eeaa-4bea-85a9-d1230142a8db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>id</th>\n",
              "      <th>filename</th>\n",
              "      <th>story</th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
              "      <td>Vatican_Library.txt</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>[{'input_text': 'When was the Vat formally ope...</td>\n",
              "      <td>[{'span_start': 151, 'span_end': 179, 'span_te...</td>\n",
              "      <td>Vatican_Library.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cnn</td>\n",
              "      <td>3wj1oxy92agboo5nlq4r7bndc3t8a8</td>\n",
              "      <td>cnn_fe05c61a7e48461f7883cdec387567029614f07b.s...</td>\n",
              "      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n",
              "      <td>[{'input_text': 'Where was the Auction held?',...</td>\n",
              "      <td>[{'span_start': 243, 'span_end': 284, 'span_te...</td>\n",
              "      <td>cnn_fe05c61a7e48461f7883cdec387567029614f07b.s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
              "      <td>data/gutenberg/txt/Zane Grey___Riders of the P...</td>\n",
              "      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n",
              "      <td>[{'input_text': 'What did Venters call Lassite...</td>\n",
              "      <td>[{'span_start': 841, 'span_end': 880, 'span_te...</td>\n",
              "      <td>data/gutenberg/txt/Zane Grey___Riders of the P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cnn</td>\n",
              "      <td>3ewijtffvo7wwchw6rtyaf7mfwte0p</td>\n",
              "      <td>cnn_0c518067e0df811501e46b2e1cd1ce511f1645b7.s...</td>\n",
              "      <td>(CNN) -- The longest-running holiday special s...</td>\n",
              "      <td>[{'input_text': 'Who is Rudolph's father?', 't...</td>\n",
              "      <td>[{'span_start': 500, 'span_end': 557, 'span_te...</td>\n",
              "      <td>cnn_0c518067e0df811501e46b2e1cd1ce511f1645b7.s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>3urfvvm165iantk80llvkwwbjs7uzh</td>\n",
              "      <td>data/gutenberg/txt/Rafael Sabatini___Love-at-A...</td>\n",
              "      <td>CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...</td>\n",
              "      <td>[{'input_text': 'Who arrived at the church?', ...</td>\n",
              "      <td>[{'span_start': 254, 'span_end': 297, 'span_te...</td>\n",
              "      <td>data/gutenberg/txt/Rafael Sabatini___Love-at-A...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8288b47d-eeaa-4bea-85a9-d1230142a8db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8288b47d-eeaa-4bea-85a9-d1230142a8db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8288b47d-eeaa-4bea-85a9-d1230142a8db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_train = pd.json_normalize(train_json['data'])\n",
        "df_test = pd.json_normalize(test_json['data'])\n",
        "# We need a different DataFrame that consider also the 'source' for the final evaluation\n",
        "df_final_evaluation = df_test.copy()\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9tsuAVrvmi9h",
      "metadata": {
        "id": "9tsuAVrvmi9h"
      },
      "source": [
        "As we can see, the sources for the dialogues are only five and they provide almost the same number of dialogues, apart from 'mctest'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eEdxQ5ALm4tu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEdxQ5ALm4tu",
        "outputId": "055ca4b9-f157-4f0c-de2e-580e707ea541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "race         1711\n",
              "cnn          1702\n",
              "wikipedia    1621\n",
              "gutenberg    1615\n",
              "mctest        550\n",
              "Name: source, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train['source'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3qaItcj1neoE",
      "metadata": {
        "id": "3qaItcj1neoE"
      },
      "source": [
        "We can also explore the number of dialogues and the average lenght of question-answer pairs for the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "H4HKsw8jnlZm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4HKsw8jnlZm",
        "outputId": "d0cf4d4c-5ada-4590-8f26-17a438044a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- The training set contains 7199 dialogues.\n",
            "\n",
            "- On average we have 15.09 question-answer pairs for each dialogue.\n"
          ]
        }
      ],
      "source": [
        "print(f\"- The training set contains {len(df_train)} dialogues.\\n\")\n",
        "print(f\"- On average we have {round(df_train['questions'].apply(lambda x: len(x)).mean(),2)}\"\n",
        "      f\" question-answer pairs for each dialogue.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "730969bf",
      "metadata": {
        "id": "730969bf"
      },
      "source": [
        "In the dataset above we have some features that are not useful for our task therefore we decided to remove them and we remained with the story for each dialogue, the questions and the relative answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "af8558f0",
      "metadata": {
        "id": "af8558f0"
      },
      "outputs": [],
      "source": [
        "features_to_remove = ['source', 'id', 'filename', 'name']\n",
        "features_to_remove_test = features_to_remove + [f'additional_answers.{i}' for i in range(3)]\n",
        "\n",
        "df_train.drop(features_to_remove, axis=1, inplace=True)\n",
        "df_test.drop(features_to_remove_test, axis=1, inplace=True)\n",
        "df_final_evaluation.drop(features_to_remove_test[1:], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6bce7aec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6bce7aec",
        "outputId": "696a06f8-d6f7-4d7b-cca0-20087b3e2126"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               story  \\\n",
              "0  The Vatican Apostolic Library (), more commonl...   \n",
              "1  New York (CNN) -- More than 80 Michael Jackson...   \n",
              "2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n",
              "3  (CNN) -- The longest-running holiday special s...   \n",
              "4  CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...   \n",
              "\n",
              "                                           questions  \\\n",
              "0  [{'input_text': 'When was the Vat formally ope...   \n",
              "1  [{'input_text': 'Where was the Auction held?',...   \n",
              "2  [{'input_text': 'What did Venters call Lassite...   \n",
              "3  [{'input_text': 'Who is Rudolph's father?', 't...   \n",
              "4  [{'input_text': 'Who arrived at the church?', ...   \n",
              "\n",
              "                                             answers  \n",
              "0  [{'span_start': 151, 'span_end': 179, 'span_te...  \n",
              "1  [{'span_start': 243, 'span_end': 284, 'span_te...  \n",
              "2  [{'span_start': 841, 'span_end': 880, 'span_te...  \n",
              "3  [{'span_start': 500, 'span_end': 557, 'span_te...  \n",
              "4  [{'span_start': 254, 'span_end': 297, 'span_te...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7905c269-183b-4abd-a684-eca48f24277a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story</th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>[{'input_text': 'When was the Vat formally ope...</td>\n",
              "      <td>[{'span_start': 151, 'span_end': 179, 'span_te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n",
              "      <td>[{'input_text': 'Where was the Auction held?',...</td>\n",
              "      <td>[{'span_start': 243, 'span_end': 284, 'span_te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n",
              "      <td>[{'input_text': 'What did Venters call Lassite...</td>\n",
              "      <td>[{'span_start': 841, 'span_end': 880, 'span_te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(CNN) -- The longest-running holiday special s...</td>\n",
              "      <td>[{'input_text': 'Who is Rudolph's father?', 't...</td>\n",
              "      <td>[{'span_start': 500, 'span_end': 557, 'span_te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...</td>\n",
              "      <td>[{'input_text': 'Who arrived at the church?', ...</td>\n",
              "      <td>[{'span_start': 254, 'span_end': 297, 'span_te...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7905c269-183b-4abd-a684-eca48f24277a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7905c269-183b-4abd-a684-eca48f24277a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7905c269-183b-4abd-a684-eca48f24277a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cd3b662",
      "metadata": {
        "id": "9cd3b662"
      },
      "source": [
        "At this point we can split the dataset in training and validation as stated in the assignment, we do that operation here because the questions are still grouped in dialogues therefore we put all the questions from one dialogue either in validation or in the training set, as specified in ***Task 2***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "IGstSaVRpVLh",
      "metadata": {
        "id": "IGstSaVRpVLh"
      },
      "outputs": [],
      "source": [
        "seeds = [42, 2022, 1337]\n",
        "\n",
        "def set_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "AK-cFhGWwTvv",
      "metadata": {
        "id": "AK-cFhGWwTvv"
      },
      "outputs": [],
      "source": [
        "def split_train_validation(df: pd.DataFrame, val_size: float=0.2) -> typing.Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    '''\n",
        "        It takes as input a dataframe and it splits it in 2 dataframes considering the \n",
        "        'val_size' parameter. \n",
        "    '''\n",
        "\n",
        "    validation = df.sample(frac=val_size) \n",
        "    training = df.drop(validation.index)\n",
        "\n",
        "    assert training is not None, \"The dataframe is None\"\n",
        "    # It shuffles the training set dialogues\n",
        "    training = training.sample(frac=1)\n",
        "\n",
        "    return training.reset_index(drop=True), validation.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6u_lmheKo0vK",
      "metadata": {
        "id": "6u_lmheKo0vK"
      },
      "source": [
        "Before splitting the training data in training and validation set we set the seed 42 for the reproducibility as requested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a63f6ff1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a63f6ff1",
        "outputId": "0acbeb09-00bf-4169-8513-1ea7993fdbca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dimensions of the datasets are:\n",
            "Training dataset -> (5759, 3) - Validation dataset -> (1440, 3)\n"
          ]
        }
      ],
      "source": [
        "set_reproducibility(seeds[0])\n",
        "df_train, df_val = split_train_validation(df_train, 0.2)\n",
        "print(f\"The dimensions of the datasets are:\\n\"\n",
        "     f\"Training dataset -> {df_train.shape} - Validation dataset -> {df_val.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JD_WpQG4pOGS",
      "metadata": {
        "id": "JD_WpQG4pOGS"
      },
      "source": [
        "We still have to unpack the array of questions and answers in order to create a row for each single element and we need to remove the unanswerable questions from the data.\n",
        "- The first function is a helper that allows us to create different rows of a DataFrame from a list of questions. \n",
        "- The second one is used to remove the unanswerable questions from the data, a question is ***unanswerable*** if the 'span_start' feature is -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "be70ee1a",
      "metadata": {
        "id": "be70ee1a"
      },
      "outputs": [],
      "source": [
        "def expand_lists(df: pd.DataFrame, to_drop: typing.List[str]=[],\n",
        "                 for_eval: bool=False) -> pd.DataFrame:\n",
        "    '''\n",
        "        Given a Pandas dataframe it returns a new dataframe with the expansion of\n",
        "        the questions and the answers and removing the desired columns.\n",
        "    '''\n",
        "    if for_eval:\n",
        "        # Add also the 'source' feature\n",
        "        assert 'source' in df.columns, \"The DataFrame has not the 'source' feature\"\n",
        "        questions = [{'source': df.source[i], 'story':df.story[i], **quest} \n",
        "                        for i, lis in enumerate(df.questions) for quest in lis]\n",
        "    else:\n",
        "        # Create a dictionary with the story and the other features for each question\n",
        "        questions = [{'story':df.story[i], **quest} for i, lis in enumerate(df.questions) for quest in lis]\n",
        "\n",
        "    answers = [ans for lis in df.answers for ans in lis]\n",
        "\n",
        "    # Create a DataFrame from the previous dictionaries and remove useless features\n",
        "    X = pd.DataFrame.from_dict(questions, orient=\"columns\").drop(to_drop, axis=1)\n",
        "    y = pd.DataFrame.from_dict(answers, orient=\"columns\").drop(to_drop, axis=1)\n",
        "\n",
        "    assert X is not None and y is not None, \"The dataframe is None\"\n",
        "    \n",
        "    X.rename(columns={'input_text':'questions'}, inplace=True)\n",
        "    y.rename(columns={'input_text':'answers'}, inplace=True)\n",
        "    \n",
        "    return pd.concat([X, y], axis=1)\n",
        "\n",
        "\n",
        "def remove_unanswerable(df: pd.DataFrame, verbose:bool=True) -> pd.DataFrame:\n",
        "    '''\n",
        "        It removes the unanswerable questions from the passed DataFrame\n",
        "        removing the elements with 'span_start' < 0\n",
        "    '''\n",
        "\n",
        "    target = 'span_start'\n",
        "    if target not in df.columns:\n",
        "        print(\n",
        "            \"WARNING: the DataFrame doesn't have the 'span_start' column, the\"\n",
        "            \" function will return the DataFrame without changes.\"\n",
        "            )\n",
        "        return df\n",
        "        \n",
        "    uns_rows = df[target] > 0\n",
        "    if verbose:\n",
        "        print(\n",
        "            f\"{len(df) - len(df[uns_rows])} unanswerable questions has been removed\"\n",
        "             \" from the DataFrame.\"\n",
        "            )\n",
        "    return df[uns_rows].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u1ufKLEVpgE8",
      "metadata": {
        "id": "u1ufKLEVpgE8"
      },
      "source": [
        "In order to make the code as ordered as possible we implemented a unique function for the preprocessing that we need to apply on the different DataFrames. It simply calls the 2 previous functions on the passed DataFrame, it removes the features about the spans and it returns the new DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "VEPGym-Q-d6K",
      "metadata": {
        "id": "VEPGym-Q-d6K"
      },
      "outputs": [],
      "source": [
        "def data_preprocessing(df: pd.DataFrame, to_drop: typing.List[str]=[],\n",
        "                       for_eval: bool=False) -> pd.DataFrame:\n",
        "    '''\n",
        "        This function creates a DataFrame with a column for the 'story', one\n",
        "        for the 'questions' and another for the 'answers' and it removes the\n",
        "        unanswerable questions.\n",
        "        Parameters:\n",
        "            - df : pd.DataFrame\n",
        "                The structure on which performing the operations.\n",
        "            - to_drop: list[str]\n",
        "                The names of the columns to drop.\n",
        "            - for_eval: bool\n",
        "                If the expand_lists function has to be run in evaluation mode,\n",
        "                so we preserve the 'source' feature.\n",
        "                \n",
        "        Returns:\n",
        "            pandas.Dataframe\n",
        "                The modified dataframe.\n",
        "    '''\n",
        "    new_df = expand_lists(df, to_drop, for_eval)\n",
        "    new_df = remove_unanswerable(new_df)\n",
        "\n",
        "    span_feat = ['span_start', 'span_end', 'span_text']\n",
        "    new_df.drop(span_feat, axis=1, inplace=True)\n",
        "\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6e6f82ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e6f82ee",
        "outputId": "d4bb6515-468f-4491-9648-915259a85fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3490 unanswerable questions has been removed from the DataFrame.\n",
            "900 unanswerable questions has been removed from the DataFrame.\n",
            "288 unanswerable questions has been removed from the DataFrame.\n",
            "288 unanswerable questions has been removed from the DataFrame.\n",
            "\n",
            "The training set has 83408 samples, the validation set has 20849 samplesand the test set has 7695 samples.\n"
          ]
        }
      ],
      "source": [
        "df_train = data_preprocessing(df_train, to_drop=['turn_id', 'bad_turn'])\n",
        "df_val = data_preprocessing(df_val, to_drop=['turn_id', 'bad_turn'])\n",
        "df_test = data_preprocessing(df_test, to_drop=['turn_id'])\n",
        "df_final_evaluation = data_preprocessing(df_final_evaluation, to_drop=['turn_id'], for_eval=True)\n",
        "\n",
        "print(f\"\\nThe training set has {len(df_train)} samples, the validation set has {len(df_val)} samples\"\n",
        "      f\"and the test set has {len(df_test)} samples.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aWpccDgqEVbs",
      "metadata": {
        "id": "aWpccDgqEVbs"
      },
      "source": [
        "At this moment the DataFrame looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ahNnLLGVEU6p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ahNnLLGVEU6p",
        "outputId": "ec4ace9d-a019-4cd4-ea7b-782820a1d3c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               story  \\\n",
              "0  CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...   \n",
              "1  CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...   \n",
              "2  CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...   \n",
              "3  CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...   \n",
              "4  CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...   \n",
              "\n",
              "                              questions  \\\n",
              "0  What color is the top of the church?   \n",
              "1                          Is it short?   \n",
              "2                   Who behaves better?   \n",
              "3                                  Why?   \n",
              "4                   Who killed himself?   \n",
              "\n",
              "                                             answers  \n",
              "0                                              green  \n",
              "1                                                 No  \n",
              "2                          the back of the Tenements  \n",
              "3  Every back window in the Tenements has a glint...  \n",
              "4                                            Beattie  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a648e9f0-e7d2-4fb7-b3be-07a95e654b76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story</th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...</td>\n",
              "      <td>What color is the top of the church?</td>\n",
              "      <td>green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...</td>\n",
              "      <td>Is it short?</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...</td>\n",
              "      <td>Who behaves better?</td>\n",
              "      <td>the back of the Tenements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...</td>\n",
              "      <td>Why?</td>\n",
              "      <td>Every back window in the Tenements has a glint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CHAPTER III. \\n\\nTHE NIGHT-WATCHERS. \\n\\nWhat ...</td>\n",
              "      <td>Who killed himself?</td>\n",
              "      <td>Beattie</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a648e9f0-e7d2-4fb7-b3be-07a95e654b76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a648e9f0-e7d2-4fb7-b3be-07a95e654b76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a648e9f0-e7d2-4fb7-b3be-07a95e654b76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yDRKGGZhhDYh",
      "metadata": {
        "id": "yDRKGGZhhDYh"
      },
      "source": [
        "## Model implementation and data tokenization [TASK 3, TASK 4, TASK 5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RIIrgApsE0LM",
      "metadata": {
        "id": "RIIrgApsE0LM"
      },
      "source": [
        "In order to train the encoder-decoder architecture we have to tokenize the samples such that we can give numbers as input to the network.\n",
        "\n",
        "In our case we will use the tokenizer of the relative pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "86ih3U7eVgy2",
      "metadata": {
        "id": "86ih3U7eVgy2"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q\n",
        "!pip install datasets -q\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "icicV7K0sEzm",
      "metadata": {
        "id": "icicV7K0sEzm"
      },
      "source": [
        "### Load the pre-trained model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "p-v8bD-1sP7i",
      "metadata": {
        "id": "p-v8bD-1sP7i"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Union, List, Tuple, Dict\n",
        "\n",
        "from datasets.arrow_dataset import Dataset\n",
        "from transformers import TFEncoderDecoderModel, AutoTokenizer\n",
        "\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5OH0olNXsTF2",
      "metadata": {
        "id": "5OH0olNXsTF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d08d5f-ac10-440a-a6d8-8dc94ab5c293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_weights_path = \"/content/drive/MyDrive/weights_NLP_assignments/\"\n",
        "drive_tokenized_path = \"/content/drive/MyDrive/weights_NLP_assignments/tok_data/\"\n",
        "\n",
        "bertiny_name = \"prajjwal1/bert-tiny\"\n",
        "roberta_name = \"distilroberta-base\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mrMByUePtCjm",
      "metadata": {
        "id": "mrMByUePtCjm"
      },
      "source": [
        "We implemented a function to import the tokenizer and the model from a pre-saved model or directly from Huggingface if no path is passed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "usyK7nEHsZBK",
      "metadata": {
        "id": "usyK7nEHsZBK"
      },
      "outputs": [],
      "source": [
        "def check_pretrained_path(path: str) -> bool:\n",
        "    '''\n",
        "        It checks if the config.json file exists in the current path.\n",
        "    '''\n",
        "    config_file = os.path.join(path, 'config.json')\n",
        "    return os.path.exists(config_file)\n",
        "\n",
        "\n",
        "def import_model_tokenizer(name: str=\"distilroberta-base\", load_weights: Optional[str]=None)->tuple:\n",
        "    '''\n",
        "        It imports the tokenizer and the model specified from the 'name' parameter.\n",
        "        If a path in 'load_weigths' is specified then it imports the model from\n",
        "        a pre-saved file.\n",
        "        Parameters:\n",
        "            - name: str\n",
        "                The name of the model we want to import, it must exist in the\n",
        "                Huggingface database.\n",
        "            - load_weights: str | None\n",
        "                The path to a directory that contains the config file and the \n",
        "                .h5 file for loading a pre-saved model.\n",
        "        \n",
        "        Returns:\n",
        "            - tuple\n",
        "                It returns the desired tokenizer and the imported model.\n",
        "    '''\n",
        "    tokenizer = AutoTokenizer.from_pretrained(name)\n",
        "    enc_from_pt = False\n",
        "\n",
        "    # If a path has been passed\n",
        "    if load_weights != None:\n",
        "        mod_name = name.split('/')[-1]\n",
        "        full_path = os.path.join(drive_weights_path, mod_name, load_weights)\n",
        "        if check_pretrained_path(full_path):\n",
        "            model = TFEncoderDecoderModel.from_pretrained(full_path)\n",
        "        else:\n",
        "            print(\"ERROR: Check if a config.json file exists in the given path.\")\n",
        "            return None, None\n",
        "    else:\n",
        "        if name != \"distilroberta-base\":\n",
        "            enc_from_pt = True\n",
        "\n",
        "        model = TFEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "            name, name, encoder_from_pt=enc_from_pt, decoder_from_pt=enc_from_pt\n",
        "        )\n",
        "        model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "        model.config_eos_token_id = tokenizer.sep_token_id\n",
        "        model.config.vocab_size = model.config.encoder.vocab_size\n",
        "\n",
        "    return tokenizer, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "FCQ8VSepsk3v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCQ8VSepsk3v",
        "outputId": "d421c99a-7463-47b1-dafe-13f317ff256c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFEncoderDecoderModel.\n",
            "\n",
            "All the layers of TFEncoderDecoderModel were initialized from the model checkpoint at /content/drive/MyDrive/weights_NLP_assignments/distilroberta-base/42_no_history.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFEncoderDecoderModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "tokenizer, model = import_model_tokenizer(roberta_name, load_weights='42_no_history')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C4RB6BoVsmgO",
      "metadata": {
        "id": "C4RB6BoVsmgO"
      },
      "source": [
        "### Tokenization function and history creation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4LQqckhmB9Nt",
      "metadata": {
        "id": "4LQqckhmB9Nt"
      },
      "source": [
        "The following function is needed to create the history for each sample, the history is composed by the 'story' of the question and all the questions and answers from the previous rows.\n",
        "The function has 3 main steps:\n",
        "- we group by 'story' in order to consider the samples belonging to the same dialogue; we create a new column 'history' in the DataFrame where we put for each line the concatenation of answer and question of the successive row. This because the first element of the history for each question is the previous one, so we need to shift by 1 such that we avoid to put the current question and answer in the history as well.\n",
        "- Now, after having grouped by 'story' again, we apply the function *cumulative sum*, it sums the previous rows of the same group to the current one.\n",
        "- As last step we sum the 'story' to the computed history and we return the DataFrame with the new column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fFPB_4uXCBIo",
      "metadata": {
        "id": "fFPB_4uXCBIo"
      },
      "outputs": [],
      "source": [
        "def create_history(df: pd.DataFrame, group: str='story') -> pd.DataFrame:\n",
        "    '''\n",
        "        This function returns the dataframe with a new column 'history' which\n",
        "        contains the sum of the story and all the questions and answers within\n",
        "        the same context, not considering the current sample.\n",
        "        Parameters:\n",
        "            - df: pd.DataFrame\n",
        "                The dataframe from which the function takes the data.\n",
        "            - group: str\n",
        "                The column to consider for the groupby operation.\n",
        "        \n",
        "        Returns:\n",
        "            - pd.DataFrame\n",
        "                The DataFrame with the new column added. \n",
        "    '''\n",
        "    new_df = df.copy()\n",
        "    sum_columns = lambda x: x.questions + ' ' + x.answers + ' '\n",
        "    # If the story has a white space at the end, we don't need to add it\n",
        "    def sum_ctx_history(row):\n",
        "        space = \" \"\n",
        "        if row.story[-1].isspace():\n",
        "            space = \"\"\n",
        "        return row.story + space + row.history\n",
        "\n",
        "    print(\"START: Creating the history column for the dataset...\")\n",
        "    # Returns a new column that contains for each sample the sum of the\n",
        "    # question and the context\n",
        "    new_df['history'] = new_df.groupby(group, axis=0, sort=False) \\\n",
        "                            .shift(fill_value='') \\\n",
        "                            .apply(sum_columns, axis=1)\n",
        "\n",
        "    # Sum the history up to the previous question for each sample\n",
        "    new_df['history'] = new_df.groupby(group, axis=0, sort=False)['history'] \\\n",
        "                            .apply(lambda x: x.cumsum()).str.strip()\n",
        "\n",
        "    new_df['history'] = new_df.apply(sum_ctx_history, axis=1)\n",
        "\n",
        "    print(\"END: The column for the history has been added to the dataset.\")\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XAX8TSBqCCXi",
      "metadata": {
        "id": "XAX8TSBqCCXi"
      },
      "source": [
        "The following functions are used to compute the tokenized answers and the tokenization of each question + the relative context (story / history). The function has a parameter that checks if the history needs to be created, if this is the case the previous function 'create_history' is called and the successive operations are performed with the new dataset.\n",
        "\n",
        "We decided to create batch of samples from the passed dataset in order to avoid the consumption of the RAM, even if we also give the possibiity to save the tokenized data in a .json file in a Drive directory, to make the loading of the data faster.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "P9L8DQnw8QnH",
      "metadata": {
        "id": "P9L8DQnw8QnH"
      },
      "outputs": [],
      "source": [
        "def apply_reduce(data, func):\n",
        "    '''\n",
        "        Apply the function on a list of elements concatenating the samples with \n",
        "        the previous results (as the reduce).\n",
        "    '''\n",
        "    res = data.pop(0)\n",
        "    for el in data:\n",
        "        res = func((res, el))\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "U1pTuqZ1FwWX",
      "metadata": {
        "id": "U1pTuqZ1FwWX"
      },
      "outputs": [],
      "source": [
        "def tokenize_samples(dataset: datasets.arrow_dataset.Dataset, tokenizer, max_embed_quest: int=512,\n",
        "                     max_embed_answ: int=30, mode: Optional[str]='np', with_history: bool=False, \n",
        "                     batch_size: int=1024)->tuple:\n",
        "    '''\n",
        "        This function returns a dictionary with the outputs of the tokenizer.\n",
        "        As input we refer to the concatenation of the quesions with the relative\n",
        "        contexts and we need both tokenization and attention mask. For the\n",
        "        answers we only need the tokenization.\n",
        "        Parameters:\n",
        "            - dataset: datasets.arrow_dataset.Dataset\n",
        "                The dataset from which the function takes the data.\n",
        "            - max_embed_quest: int\n",
        "                The maximum length for the sequence context + questions, in our \n",
        "                case is 512.\n",
        "            - max_embed_answ: int\n",
        "                The maximum length for the tokenized answers.\n",
        "            - mode: bool\n",
        "                Wheter the tokenizer could return the outputs as lists of python\n",
        "                integers, 'tf' tensors, 'np' arrays or 'pt' for pytorch tensors.\n",
        "            - with_history: bool\n",
        "                If True then we concatenate the question with the history instead \n",
        "                of the simple context.\n",
        "            - batch_size: int\n",
        "                The batch size to use in for computing the tokenization.\n",
        "        Returns:\n",
        "            - tuple\n",
        "                A tuple with the tokenized questions+contexts, their relative\n",
        "                attention masks and the tokenized answers.\n",
        "                If 'with_history' is True it also returns the new dataset\n",
        "                with the history, the passed dataset otherwise.\n",
        "    '''\n",
        "    if with_history:\n",
        "        pandas_dataset = dataset.to_pandas()\n",
        "        assert isinstance(pandas_dataset, pd.DataFrame)\n",
        "\n",
        "        new_dataset = Dataset.from_pandas(create_history(pandas_dataset))\n",
        "        context = new_dataset[\"history\"]\n",
        "    else:\n",
        "        new_dataset = dataset\n",
        "        context = dataset['story']\n",
        "\n",
        "    ids = []\n",
        "    masks = []\n",
        "    ys = []\n",
        "\n",
        "    num_steps = len(new_dataset) // batch_size\n",
        "    last_batch_size = len(new_dataset) - (batch_size*num_steps)\n",
        "\n",
        "    for i in range(num_steps+1):\n",
        "        start = batch_size * i\n",
        "        # If we are in the last batch and it's > 0\n",
        "        if i >= num_steps:\n",
        "            if last_batch_size > 0:\n",
        "                batch_size = last_batch_size\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # Take a batch of samples\n",
        "        batch_quest = new_dataset['questions'][start:start+batch_size]\n",
        "        batch_ctx = context[start:start+batch_size]\n",
        "        batch_answ = new_dataset['answers'][start:start+batch_size]\n",
        "        \n",
        "        # Tokenize the batch\n",
        "        x_tok_batch = tokenizer(\n",
        "            batch_quest,\n",
        "            batch_ctx,\n",
        "            max_length=max_embed_quest,\n",
        "            truncation=\"only_second\",\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=mode,\n",
        "            return_token_type_ids=False\n",
        "        )\n",
        "        y_tok_batch = tokenizer(\n",
        "            batch_answ,\n",
        "            max_length=max_embed_answ,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=mode,\n",
        "            return_token_type_ids=False\n",
        "        )\n",
        "        # Create 3 lists for the results\n",
        "        ids.append(x_tok_batch['input_ids'])\n",
        "        masks.append(x_tok_batch['attention_mask'])\n",
        "        ys.append(y_tok_batch['input_ids'])\n",
        "    \n",
        "    # Merge the results of the different batches concatenating them\n",
        "    X_tok = {'input_ids': apply_reduce(ids, np.concatenate), \n",
        "             'attention_mask': apply_reduce(masks, np.concatenate)}\n",
        "    y_tok = apply_reduce(ys, np.concatenate)\n",
        "    \n",
        "    return X_tok, y_tok, new_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pGrX37BsSQaM",
      "metadata": {
        "id": "pGrX37BsSQaM"
      },
      "source": [
        "### EXPERIMENTAL TOKENIZATION AND BATCH\n",
        "\n",
        "I implemented an alternative version of the function in which I use the map built-in function to tokenize in batch the datasets. It's less efficient but the code is more readable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TaX6j6H2SZN_",
      "metadata": {
        "id": "TaX6j6H2SZN_"
      },
      "outputs": [],
      "source": [
        "def apply_tok(sample, tokenizer, ctx='story', max_embed=512, max_embed_answ=30):\n",
        "    '''\n",
        "        The function that will be applied to all the rows of the dataset.\n",
        "    '''\n",
        "    x_tok_batch = tokenizer(\n",
        "        sample['questions'],\n",
        "        sample[ctx],\n",
        "        max_length=max_embed,\n",
        "        truncation=\"only_second\",\n",
        "        padding=\"max_length\",\n",
        "        return_tensors='np',\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "    y_tok_batch = tokenizer(\n",
        "        sample['answers'],\n",
        "        max_length=max_embed_answ,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors='np',\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "    return {'input_ids':x_tok_batch['input_ids'],'attention_mask':x_tok_batch['attention_mask'],\n",
        "            'tok_answers':y_tok_batch['input_ids']}\n",
        "\n",
        "\n",
        "def experimental_tok(dataset: datasets.arrow_dataset.Dataset, tokenizer, max_embed_quest: int=512,\n",
        "            max_embed_answ: int=30, mode: Optional[str]='np', with_history: bool=False, \n",
        "            batch_size: int=1024):\n",
        "    '''\n",
        "        An alternative tokenization function.\n",
        "    '''\n",
        "    \n",
        "    if with_history:\n",
        "        pandas_dataset = dataset.to_pandas()\n",
        "        assert isinstance(pandas_dataset, pd.DataFrame)\n",
        "\n",
        "        new_dataset = Dataset.from_pandas(create_history(pandas_dataset))\n",
        "        context = \"history\"\n",
        "    else:\n",
        "        new_dataset = dataset\n",
        "        context = 'story'\n",
        "\n",
        "    tok_ds = new_dataset.map(apply_tok, batched=True, batch_size=batch_size, \n",
        "                        fn_kwargs={'tokenizer': tokenizer, 'ctx': context, \n",
        "                                   'max_embed':max_embed_quest, \n",
        "                                   'max_embed_answ': max_embed_answ}\n",
        "                             )\n",
        "    x_tok = {'input_ids': np.array(tok_ds['input_ids']), \n",
        "             'attention_mask': np.array(tok_ds['attention_mask'])}\n",
        "    y_tok = np.array(tok_ds['tok_answers'])\n",
        "\n",
        "    return x_tok, y_tok, new_dataset\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8EXn3NrYo6D",
      "metadata": {
        "id": "b8EXn3NrYo6D"
      },
      "source": [
        "### Tokenize data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BaahRWYRyeML",
      "metadata": {
        "id": "BaahRWYRyeML"
      },
      "source": [
        "Actually before tokenization occurs we create the Dataset objects (Huggingface) from the DataFrames. Then the tokenization function returns as result a dictionary of numpy array ('input_ids' and 'attention_mask') that is used as input for the model and a numpy array for the tokenized answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "CSDEDS1XzjXQ",
      "metadata": {
        "id": "CSDEDS1XzjXQ"
      },
      "outputs": [],
      "source": [
        "dataset_train = Dataset.from_pandas(df_train)\n",
        "dataset_val = Dataset.from_pandas(df_val)\n",
        "dataset_test = Dataset.from_pandas(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60g6Nu2z8QE",
      "metadata": {
        "id": "f60g6Nu2z8QE"
      },
      "source": [
        "#### Load pre-saved tokenized data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vso3dvQv2aBE",
      "metadata": {
        "id": "Vso3dvQv2aBE"
      },
      "source": [
        "If you prefer to load the tokenized data from .json files. \n",
        "\n",
        "The .json files, one for training, validation and test, contain:\n",
        "- 'input_ids': the tokenization of the concatenation of the answer and the context (+ the history if selected);\n",
        "- 'attention_mask': the attention masks for the input_ids;\n",
        "- 'labels': the target arrays that represent the tokenized answers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "z2St3eHn0FT1",
      "metadata": {
        "id": "z2St3eHn0FT1"
      },
      "outputs": [],
      "source": [
        "def load_tokenized_dict(file_path: str) -> Union[Tuple[Dict, np.ndarray], Tuple[None, None]]:\n",
        "    '''\n",
        "        It load the .json file from the given path, it convert the lists to numpy\n",
        "        arrays and at the end it returns a dictionary with 'input_ids' and \n",
        "        'attention_mask' and the array of the tokenized answers.\n",
        "        Parameters:\n",
        "            - file_path: str\n",
        "                The path of the .json file from which we read the data.\n",
        "            \n",
        "        Returns:\n",
        "            - Tuple[Dict[np.ndarray, np.ndarray], np.ndarray] | Tuple[None, None]\n",
        "                A tuple, the dictionary with the 'input_ids' and the 'attention_mask'\n",
        "                numpy arrays if the path exists, None otherwise.\n",
        "    '''\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r') as fin:\n",
        "            data = json.load(fin)\n",
        "        # It takes the labels and delete them from the dict\n",
        "        y_labels = data['labels']\n",
        "        del data['labels']\n",
        "\n",
        "        data['input_ids'] = np.array(data['input_ids'])\n",
        "        data['attention_mask'] = np.array(data['attention_mask'])\n",
        "\n",
        "        return data, np.array(y_labels) \n",
        "    else:\n",
        "        print(f\"ERROR: a file doesn't exist in the specified path: {file_path}.\")\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "yjSYd91n0Hou",
      "metadata": {
        "id": "yjSYd91n0Hou"
      },
      "outputs": [],
      "source": [
        "#  Import the tokenized data from the json files\n",
        "load_dir = 'no_history'\n",
        "is_hist = '_hist' if load_dir=='history' else ''\n",
        "model_name = roberta_name\n",
        "\n",
        "x_train, y_train = load_tokenized_dict(os.path.join(\n",
        "                    drive_tokenized_path, load_dir, model_name, f'train_tok{is_hist}.json'))\n",
        "\n",
        "x_val, y_val = load_tokenized_dict(os.path.join(\n",
        "                    drive_tokenized_path, load_dir, model_name, f'val_tok{is_hist}.json'))\n",
        "\n",
        "x_test, y_test = load_tokenized_dict(os.path.join(\n",
        "                    drive_tokenized_path, load_dir, model_name, f'test_tok{is_hist}.json'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q7FiFQD0Yv-n",
      "metadata": {
        "id": "Q7FiFQD0Yv-n"
      },
      "source": [
        "#### Compute tokenization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fJhsbxH04DJ",
      "metadata": {
        "id": "6fJhsbxH04DJ"
      },
      "outputs": [],
      "source": [
        "# Compute the tokenized data, if you specify a different dimension, only on a subset\n",
        "# of the dataset.\n",
        "train_samples = len(dataset_train)\n",
        "val_samples = len(dataset_val)\n",
        "history = False\n",
        "\n",
        "x_train, y_train, hist_train_dataset = tokenize_samples(\n",
        "    dataset_train.select(range(train_samples)),\n",
        "    tokenizer, with_history=history, batch_size=16384\n",
        "    )\n",
        "\n",
        "x_val, y_val, hist_val_dataset = tokenize_samples(\n",
        "    dataset_val.select(range(val_samples)),\n",
        "    tokenizer, with_history=history, batch_size=4096\n",
        "    )\n",
        "\n",
        "x_test, y_test, hist_test_dataset = tokenize_samples(\n",
        "    dataset_test, tokenizer, with_history=history, batch_size=1024\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5KDoYgi13amI",
      "metadata": {
        "id": "5KDoYgi13amI"
      },
      "source": [
        "##### Save tokenized data in .json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7QxfGi7HnwkD",
      "metadata": {
        "id": "7QxfGi7HnwkD"
      },
      "outputs": [],
      "source": [
        "def save_tokenized_dict(x_data: dict, y_data: np.ndarray, file_path: str='./tokenized.json'):\n",
        "    '''\n",
        "        It saves the given data, a dictionary with 'input_ids' and \n",
        "        'attention_mask', as a .json file in the given_path. The values in the\n",
        "        x_data needs to be numpy arrays otherwise an error is raised due to the\n",
        "        'tolist()' function. \n",
        "        Parameters:\n",
        "            - x_data: dict\n",
        "                The dictionary that contains 'input_ids' and 'attention_mask'.\n",
        "            - y_data: np.ndarray\n",
        "                The array of tokenized answers.\n",
        "            - file_path: str\n",
        "                The path where the file will be saved.\n",
        "    '''\n",
        "    new_dict = x_data.copy()\n",
        "    new_dict['input_ids'] = new_dict['input_ids'].tolist()\n",
        "    new_dict['attention_mask'] = new_dict['attention_mask'].tolist()\n",
        "    # Add the labels to compress all in a unique json\n",
        "    new_dict['labels'] = y_data.tolist()\n",
        "\n",
        "    with open(file_path, 'w+') as fout:\n",
        "        json.dump(new_dict, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cL1B2CsTnyKF",
      "metadata": {
        "id": "cL1B2CsTnyKF"
      },
      "outputs": [],
      "source": [
        "save_to = 'no_history'\n",
        "is_history_save = '_hist' if save_to=='history' else ''\n",
        "model_name = roberta_name\n",
        "\n",
        "save_tokenized_dict(\n",
        "    x_train, y_train, \n",
        "    os.path.join(drive_tokenized_path, save_to, model_name, f'train_tok{is_history_save}.json')\n",
        "    )\n",
        "\n",
        "save_tokenized_dict(\n",
        "    x_val, y_val,\n",
        "    os.path.join(drive_tokenized_path, save_to, model_name, f'val_tok{is_history_save}.json')\n",
        "    )\n",
        "\n",
        "save_tokenized_dict(\n",
        "    x_test, y_test, \n",
        "    os.path.join(drive_tokenized_path, save_to, model_name, f'test_tok{is_history_save}.json')\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zP9VsaqkfIhm",
      "metadata": {
        "id": "zP9VsaqkfIhm"
      },
      "source": [
        "### Train the model [TASK 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71xy7mv_fRKb",
      "metadata": {
        "id": "71xy7mv_fRKb"
      },
      "outputs": [],
      "source": [
        "def train_model(model: TFEncoderDecoderModel, X_train: dict, y_train: np.ndarray, epochs: int=3,\n",
        "                batch_size: int=32, optimizer: keras.optimizers.Optimizer=Adam(1e-5),\n",
        "                X_val: Optional[dict]=None, y_val: Optional[dict]=None) -> keras.callbacks.History:\n",
        "    '''\n",
        "        It trains the given model for the specified number of epochs, the given\n",
        "        optimizer and the given batch. It returns the history\n",
        "        Parameters:\n",
        "            - model: TFEncoderDecoderModel\n",
        "                The encoder decoder model to train on the data.\n",
        "            - X_train: dict\n",
        "                The dictionary that contains 'input_ids' and 'attention_mask'\n",
        "                arrays.\n",
        "            - y_train: np.ndarray\n",
        "                The array of the tokenized answers.\n",
        "            - epochs: int\n",
        "                The number of epochs to train the model for.\n",
        "            - batch_size: int\n",
        "                The batch size to use during the training.\n",
        "            - optimizer: keras.optimizers.Optimizer\n",
        "                The optimizer to consider for the training.\n",
        "            - X_val: dict | None\n",
        "                The X data for the validation dataset.\n",
        "            - y_val: dict | None\n",
        "                The y data for the validation dataset.\n",
        "        \n",
        "        Returns:\n",
        "            - keras.callbacks.History\n",
        "                The history of the training.\n",
        "    '''\n",
        "    validation_data = None if (X_val is None or y_val is None) else (X_val, y_val) \n",
        "\n",
        "    model.compile(optimizer=optim)\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                        validation_data=validation_data)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dgtYeRav5DdT",
      "metadata": {
        "id": "dgtYeRav5DdT"
      },
      "source": [
        "We only need to fine-tune the model on our data so we keep a low learning rate."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_dataset(x, y, red_samples):\n",
        "    x_red = {\n",
        "        'input_ids': x['input_ids'][:red_samples],\n",
        "        'attention_mask': x['attention_mask'][:red_samples]\n",
        "        }\n",
        "    y_red = y[:red_samples]\n",
        "\n",
        "    return x_red, y_red"
      ],
      "metadata": {
        "id": "buBmeA61FrFc"
      },
      "id": "buBmeA61FrFc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xTKA9ZKPKd22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTKA9ZKPKd22",
        "outputId": "824d1f10-aed1-4aad-c3e2-e6f3f53fd5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:371: FutureWarning: Version v4.17.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.17.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  return py_builtins.overload_of(f)(*args)\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_encoder_decoder_model/encoder/roberta/pooler/dense/kernel:0', 'tf_encoder_decoder_model/encoder/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_encoder_decoder_model/encoder/roberta/pooler/dense/kernel:0', 'tf_encoder_decoder_model/encoder/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 904s 1s/step - loss: 1.2658 - val_loss: 0.9859\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 882s 1s/step - loss: 0.9134 - val_loss: 0.9226\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 883s 1s/step - loss: 0.8200 - val_loss: 0.8682\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "lr=3e-5\n",
        "optim = Adam(lr)\n",
        "\n",
        "set_reproducibility(seeds[0])\n",
        "# Reduce the batch size and number of samples to avoid OOM and too long training time\n",
        "if 'roberta' in model.config.encoder.name_or_path:\n",
        "    red_train = 10000\n",
        "    red_val = 2000\n",
        "    batch_size = 16\n",
        "\n",
        "    x_train_red, y_train_red = reduce_dataset(x_train, y_train, red_train)\n",
        "    x_val_red, y_val_red = reduce_dataset(x_val, y_val, red_val)\n",
        "\n",
        "    history = train_model(model, x_train_red, y_train_red, epochs, batch_size, optim, \n",
        "                      x_val_red, y_val_red)\n",
        "else:\n",
        "    batch_size = 32\n",
        "    history = train_model(model, x_train, y_train, epochs, batch_size, optim, \n",
        "                      x_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Qaj_AVOwhzo",
      "metadata": {
        "id": "2Qaj_AVOwhzo"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(os.path.join(drive_weights_path, roberta_name, '42_no_history'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute squad f1 score"
      ],
      "metadata": {
        "id": "AwS-X-YdsiFH"
      },
      "id": "AwS-X-YdsiFH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In order to compute the squad f1 score we decided to use the [squad metric](https://huggingface.co/spaces/evaluate-metric/squad) from Huggingface. \n",
        "\n",
        "To avoid problem with RAM allocation (model.generate gave OOM error if we tried to run on the full test set), we generate batch of results and then we merge them together before computing the f1 score.\n",
        "\n",
        "If you are testing and an OOM error occur try to reduce the batch size or the number of samples, because if the RAM has already been filled during different computations it may happen. Otherwise restart the runtime and load the pre-tokenized weights and pre-trained model from Drive such that the RAM is almost completely free."
      ],
      "metadata": {
        "id": "_IsS5Gupssy7"
      },
      "id": "_IsS5Gupssy7"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate -q\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "vfbgHurwswkO"
      },
      "id": "vfbgHurwswkO",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_metric = evaluate.load(\"squad\")"
      ],
      "metadata": {
        "id": "YUN5gTjzsFNS"
      },
      "id": "YUN5gTjzsFNS",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_f1_score(model: TFEncoderDecoderModel, X: dict, answers: List[str],\n",
        "                     metric: evaluate.EvaluationModule, tokenizer,\n",
        "                     num_samples: Optional[int]=None, max_length: int=20, batch_size: int=500, \n",
        "                     return_pred_answers: bool=False) -> Tuple[float, list]:\n",
        "    '''\n",
        "        This function takes as input a dataset, it runs inference on the given\n",
        "        model and then it returns the F1 score metric.\n",
        "        Parameters:\n",
        "            - model: transformers.models\n",
        "                The model to run inference on.\n",
        "            - X: dict\n",
        "                The structure that contains the input_ids and attention_mask, it\n",
        "                is obtained doing 'variable.data' on an object of type\n",
        "                transformers.tokenization_utils_base.BatchEncoding.\n",
        "            - answers: list\n",
        "                The array of strings of answers.\n",
        "            - metric: evaluate.Metric\n",
        "                It's the metric object to consider for the computation.\n",
        "            - tokenizer:\n",
        "                The tokenizer of the model.\n",
        "            - num_samples: int \n",
        "                The function takes from the samples the first 'num_samples'\n",
        "                samples.\n",
        "            - max_length: int\n",
        "                It's the maximum length used during the generation\n",
        "            - batch_size: int\n",
        "                It's the batch size used to pass this number of answers to the \n",
        "                model (to avoid RAM allocation error).\n",
        "            - return_pred_answers: bool\n",
        "                If the function has to return the array of predicted answers.\n",
        "\n",
        "        Returns:\n",
        "            - (float, list)\n",
        "                The f1 score and the array of predicted answers if return_pred_answers\n",
        "                is True, only the f1 score and an empty list otherwise.\n",
        "    '''\n",
        "    # Take all the samples\n",
        "    if num_samples == None:\n",
        "        num_samples = len(answers)\n",
        "    \n",
        "    assert num_samples > batch_size, \"ERROR: the batch size is greater than the number of samples.\"\n",
        "    \n",
        "    ids, att_mask = X['input_ids'][:num_samples], X['attention_mask'][:num_samples]\n",
        "\n",
        "    num_step = num_samples//batch_size\n",
        "    # The last batch may be smaller than the batch_size \n",
        "    last_batch_size = num_samples - (num_step*batch_size)\n",
        "\n",
        "    predicted_answers = []\n",
        "    for i in tqdm(range(num_step+1)):\n",
        "        start = batch_size*(i)\n",
        "\n",
        "        # Check if it has to run the last batch with a different size\n",
        "        if i >= num_step:\n",
        "            if last_batch_size > 0:\n",
        "                batch_size = last_batch_size\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        out = model.generate(ids[start:start+batch_size], \n",
        "                             attention_mask=att_mask[start:start+batch_size],\n",
        "                             max_length=max_length).numpy()\n",
        "\n",
        "        refs = []\n",
        "        preds = []\n",
        "        for j in range(start, start+batch_size):\n",
        "            # The model output is always of 'batch_size' elements so I need to\n",
        "            # access the j - start element\n",
        "            pred_string = tokenizer.decode(out[j-start], skip_special_tokens=True)\n",
        "            if return_pred_answers:\n",
        "                predicted_answers.append(pred_string)\n",
        "\n",
        "            preds.append({'prediction_text':pred_string, 'id':str(j)})\n",
        "            refs.append({'answers': {'text':[answers[j]],'answer_start':[0],},'id':str(j)})\n",
        "\n",
        "        metric.add_batch(predictions=preds, references=refs)\n",
        "\n",
        "    f1_score = metric.compute()\n",
        "    assert f1_score is not None\n",
        "    \n",
        "    return f1_score['f1'], predicted_answers"
      ],
      "metadata": {
        "id": "MS2qxOyvszYQ"
      },
      "id": "MS2qxOyvszYQ",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bert-tiny models"
      ],
      "metadata": {
        "id": "ir9nt1qwbkvb"
      },
      "id": "ir9nt1qwbkvb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bert-tiny seed 42"
      ],
      "metadata": {
        "id": "e2WHzAP0boZV"
      },
      "id": "e2WHzAP0boZV"
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "B913HKO4brTD"
      },
      "id": "B913HKO4brTD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bert-tiny seed 2022"
      ],
      "metadata": {
        "id": "I3sK03-Ubs-L"
      },
      "id": "I3sK03-Ubs-L"
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "KfYQx_ocbwbH"
      },
      "id": "KfYQx_ocbwbH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bert-tiny seed 1337"
      ],
      "metadata": {
        "id": "-aYGDoUWbxxd"
      },
      "id": "-aYGDoUWbxxd"
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "NMB4mCbFb0XD"
      },
      "id": "NMB4mCbFb0XD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distilroberta-base models"
      ],
      "metadata": {
        "id": "qob7laawl5bN"
      },
      "id": "qob7laawl5bN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distilroberta-base seed 42"
      ],
      "metadata": {
        "id": "tS8vj3vkivit"
      },
      "id": "tS8vj3vkivit"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824d1f10-aed1-4aad-c3e2-e6f3f53fd5bd",
        "id": "IdjRk-nflvmE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:371: FutureWarning: Version v4.17.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.17.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  return py_builtins.overload_of(f)(*args)\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_encoder_decoder_model/encoder/roberta/pooler/dense/kernel:0', 'tf_encoder_decoder_model/encoder/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_encoder_decoder_model/encoder/roberta/pooler/dense/kernel:0', 'tf_encoder_decoder_model/encoder/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 904s 1s/step - loss: 1.2658 - val_loss: 0.9859\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 882s 1s/step - loss: 0.9134 - val_loss: 0.9226\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 883s 1s/step - loss: 0.8200 - val_loss: 0.8682\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "lr=3e-5\n",
        "optim = Adam(lr)\n",
        "\n",
        "set_reproducibility(seeds[0])\n",
        "# Reduce the batch size and number of samples to avoid OOM and too long training time\n",
        "if 'roberta' in model.config.encoder.name_or_path:\n",
        "    red_train = 10000\n",
        "    red_val = 2000\n",
        "    batch_size = 16\n",
        "\n",
        "    x_train_red, y_train_red = reduce_dataset(x_train, y_train, red_train)\n",
        "    x_val_red, y_val_red = reduce_dataset(x_val, y_val, red_val)\n",
        "\n",
        "    history = train_model(model, x_train_red, y_train_red, epochs, batch_size, optim, \n",
        "                      x_val_red, y_val_red)\n",
        "else:\n",
        "    batch_size = 32\n",
        "    history = train_model(model, x_train, y_train, epochs, batch_size, optim, \n",
        "                      x_val, y_val)\n"
      ],
      "id": "IdjRk-nflvmE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s9RkOY87T9_n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "s9RkOY87T9_n",
        "outputId": "41a13612-2a35-4c02-8665-cdcefa3387de"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_loss(history, min_y, max_y):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylim(min_y, max_y)\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "plot_loss(history, 0.7, 1.4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_nohist_42_test, pred_answers = compute_f1_score(model, x_test, dataset_test['answers'],\n",
        "                            f1_metric, num_samples=None, max_length=20, \n",
        "                            batch_size=64, return_pred_answers=True)\n",
        "\n",
        "print(f\"The f1 score on the test set is {round(f1_nohist_42_test,2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhojKmw2rtMn",
        "outputId": "1b32ee59-2f8c-4e06-b6ba-0e2aeb9db97a"
      },
      "id": "AhojKmw2rtMn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The f1 score on the test set is 11.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We used the same number of samples of the test set to have a better comparison\n",
        "f1_nohist_42_val, pred_answers = compute_f1_score(model, x_val, dataset_val['answers'],\n",
        "                            f1_metric, num_samples=len(y_test), max_length=20, \n",
        "                            batch_size=64, return_pred_answers=True)\n",
        "\n",
        "print(f\"The f1 score on the validation set is {round(f1_nohist_42_val,2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5XxNQgv5Iyi",
        "outputId": "5ac0e9ca-9560-434c-8be9-d288b418f038"
      },
      "id": "x5XxNQgv5Iyi",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The f1 score on the validation set is 10.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distilroberta-base seed 2022"
      ],
      "metadata": {
        "id": "Ju27ZRiJbI_C"
      },
      "id": "Ju27ZRiJbI_C"
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "QpOxJw5JbOct"
      },
      "id": "QpOxJw5JbOct",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distilroberta-base seed 1337"
      ],
      "metadata": {
        "id": "ffJy4f8YbYer"
      },
      "id": "ffJy4f8YbYer"
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "HhHtuA44bcbr"
      },
      "id": "HhHtuA44bcbr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose the model you want to test furtherly"
      ],
      "metadata": {
        "id": "L1fgRpTD6XpZ"
      },
      "id": "L1fgRpTD6XpZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We had the idea to make you choose which model you want to test furtherly checking manually some questions or retrieving the top / worst 5 questions, dialogues and so on. You can choose between all the models available in the Drive shared folder, if you didn't run the beginning of the notebook you can pass nothing to the following function and it will load automatically the model that you chose, and the data needed for the test (for example the tokenized data for the test)."
      ],
      "metadata": {
        "id": "JJw67SzI7JIP"
      },
      "id": "JJw67SzI7JIP"
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "from keras.backend import clear_session\n",
        "from numba import cuda \n",
        "from IPython.display import display\n",
        "\n",
        "#@title Get available models\n",
        "def retrieve_available_models(path=None):\n",
        "    if path is None:\n",
        "        bert_path = os.path.join(drive_weights_path, bertiny_name.split('/')[-1])\n",
        "        roberta_path = os.path.join(drive_weights_path, roberta_name)\n",
        "        paths = [bert_path, roberta_path]\n",
        "    else:\n",
        "        paths = [path]\n",
        "\n",
        "    models = []\n",
        "    for p in paths:\n",
        "        if os.path.exists(p):\n",
        "            for mod in os.listdir(p):\n",
        "                # Return the name of the model and the path where it is\n",
        "                name = p.split('/')[-1]\n",
        "                models.append((os.path.join(name, mod), os.path.join(p, mod)))\n",
        "        else:\n",
        "            print(f\"ERROR: the path {p} doesn't exist or is not available.\")\n",
        "    return models\n",
        "\n",
        "def free_ram():\n",
        "    '''\n",
        "        Free some gpu memory and ram. \n",
        "    '''\n",
        "    if 'model' in locals():\n",
        "        del model\n",
        "    gc.collect()\n",
        "    clear_session()\n",
        "    device = cuda.get_current_device()\n",
        "    #device.reset()\n",
        "\n",
        "\n",
        "def prepare_evaluation(btn): \n",
        "    '''\n",
        "        It imports the selected model, delete the previous one loaded in the memory\n",
        "        and return it.\n",
        "    '''\n",
        "    # Load the desired model\n",
        "    path = model_sel.value\n",
        "    tok_name = bertiny_name if 'bert-tiny' in path else roberta_name\n",
        "\n",
        "    free_ram()\n",
        "\n",
        "    print('\\nImporting the selected model and the relative tokenizer ...')\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tok_name)\n",
        "    model = TFEncoderDecoderModel.from_pretrained(path)\n",
        "\n",
        "    if 'pred_answers' not in locals():\n",
        "        print(\"\\nWARNING: you need the predicted_answers variable in order to proceed with the\"\n",
        "              \" evaluation, make sure to compute them with 'compute_f1_score' function.\")\n",
        "    elif 'dataset_test' not in locals():\n",
        "        print(\"\\nWARNING: dataset_test variable not found in the environment.\")\n",
        "\n",
        "    btn.imported_model = model\n",
        "    btn.imported_tokenizer = tokenizer\n",
        "    print('\\nThe model and the tokenizer have been saved successfully!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ygs1PUUC8esG"
      },
      "id": "Ygs1PUUC8esG",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, Layout, Button, VBox\n",
        "\n",
        "#@title Select the model \n",
        "available_models = retrieve_available_models()\n",
        "\n",
        "model_sel = widgets.Dropdown(\n",
        "    options=available_models,\n",
        "    description='<font size=3>Choose the model to use for the evaluation:</font>',\n",
        ")\n",
        "model_sel.layout = Layout(width='40%', height = '40px')\n",
        "model_sel.style = {'description_width': 'initial'}\n",
        "confirm_btn = Button(description='Confirm model', style={'font_weight': '600'})\n",
        "box = VBox([model_sel, confirm_btn])\n",
        "display(box)   \n",
        "\n",
        "confirm_btn.on_click(prepare_evaluation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "e79a4d3f7f9b45a3938bbf3d5fcab56f",
            "57c99948d1484714bef0817f885ef9f4",
            "1dbad66ef56b4e1e9a017cba84815635",
            "c0400af409b24c039f349070ebafa00b",
            "6293ac27c02c4d5d9073c77a239db6bd",
            "da866412e23b4c30bf95aeb8b2a5498a",
            "3d8e61fefffc4dab98d0fa5437afb404",
            "6936957dc27642c5b6120329dd63804b"
          ]
        },
        "cellView": "form",
        "id": "s1QFLumG6gLc",
        "outputId": "81473c22-f572-455b-acad-a07759c561bc"
      },
      "id": "s1QFLumG6gLc",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='<font size=3>Choose the model to use for the evaluation:</font>', layout="
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e79a4d3f7f9b45a3938bbf3d5fcab56f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Importing the selected model and the relative tokenizer ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFEncoderDecoderModel.\n",
            "\n",
            "All the layers of TFEncoderDecoderModel were initialized from the model checkpoint at /content/drive/MyDrive/weights_NLP_assignments/bert-tiny/full_history.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFEncoderDecoderModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: you need the predicted_answers variable in order to proceed with the evaluation, go back and compute them with 'compute_f1_score' function.\n",
            "\n",
            "The model and the tokenizer have been saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = confirm_btn.imported_model\n",
        "tokenizer = confirm_btn.imported_tokenizer"
      ],
      "metadata": {
        "id": "TtO5F9UJOc_D"
      },
      "id": "TtO5F9UJOc_D",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you change the model with respect to the last run, the predicted answers are of a different model, so you should compute the f1 score and predict the answers again to have the result of the current model. Same for x_test and the other tokenized structures, because bert-tiny and roberta tokenize in a different way."
      ],
      "metadata": {
        "id": "JPEnv8snZfEb"
      },
      "id": "JPEnv8snZfEb"
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, _, _ = tokenize_samples(\n",
        "    dataset_test, tokenizer, with_history=True, batch_size=1024\n",
        ")\n",
        "curr_f1_score, pred_answers = compute_f1_score(model, x_test, dataset_test['answers'],\n",
        "                                               f1_metric, tokenizer, batch_size=500,\n",
        "                                               return_pred_answers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHWO-AvOZ2bl",
        "outputId": "6208a7ba-6d93-4ecd-dba2-8edf6bb4c765"
      },
      "id": "aHWO-AvOZ2bl",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START: Creating the history column for the dataset...\n",
            "END: The column for the history has been added to the dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 16/16 [00:22<00:00,  1.41s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check model answers"
      ],
      "metadata": {
        "id": "9w6fsjOGtG_y"
      },
      "id": "9w6fsjOGtG_y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implemented one function to see the answers that the model gives, on one question or on multiple ones."
      ],
      "metadata": {
        "id": "aRFgtoRutQmF"
      },
      "id": "aRFgtoRutQmF"
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model: TFEncoderDecoderModel, dataset: datasets.arrow_dataset.Dataset,\n",
        "               tokenizer, max_length:int=20, idx_sample: Union[int, List[int]]=88, \n",
        "               with_history=False) -> None:\n",
        "    '''\n",
        "        This function takes as input a dataset, it runs inference on the given\n",
        "        model and then it prints the question, the real answer and the predicted\n",
        "        one.\n",
        "        Parameters:\n",
        "            - model: transformers.models\n",
        "                The model to run inference on.\n",
        "            - dataset: datasets.arrow_dataset.Dataset\n",
        "                The dataset from which the function takes the samples.\n",
        "            - tokenizer: \n",
        "                The tokenizer of the model.\n",
        "            - max_length: int\n",
        "                It's the maximum length allowed during the generation.\n",
        "            - idx_sample: int | list[int]\n",
        "                If an integer is passed, then the function computes the answer\n",
        "                for a single sample, otherwise for each sample specified in the\n",
        "                list (through the index).\n",
        "            - with_history: bool\n",
        "                if to tokenize with the history or not.\n",
        "\n",
        "        Return:\n",
        "            The function simply prints the results without returning anything.\n",
        "    '''\n",
        "    if isinstance(idx_sample, int):\n",
        "        idx_sample = [idx_sample]\n",
        "\n",
        "    # Check if indices are without dataset bounds    \n",
        "    max_ind = max(idx_sample)\n",
        "    if max_ind >= len(dataset):\n",
        "        print(f\"Error: index {max_ind} is out of bounds (dataset of length {len(dataset)}.\")\n",
        "        return None\n",
        "\n",
        "    for idx in idx_sample:\n",
        "        inp_test, _, _ = tokenize_samples(dataset.select([idx]), tokenizer, with_history=with_history)\n",
        "\n",
        "        greedy_output = model.generate(inp_test['input_ids'],\n",
        "                                       attention_mask=inp_test['attention_mask'],\n",
        "                                       max_length=max_length)# decoder_start_token_id=model.config.decoder.bos_token_id\n",
        "\n",
        "        print(f\"- The question {idx+1} is:\\n\\t{dataset[idx]['questions']}\")\n",
        "        print(f\"- The actual answer is:\\n\\t{dataset[idx]['answers']}\")\n",
        "        print(f\"- The predicted answer is:\\n\\t\"\n",
        "              f\"{tokenizer.decode(greedy_output.numpy()[0], skip_special_tokens=True)}\\n\")"
      ],
      "metadata": {
        "id": "cGlRpvb_tLsv"
      },
      "id": "cGlRpvb_tLsv",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca9c0f7-2c60-4c1a-a761-2c72ee0a5b85",
        "id": "SAPTA4X1tf_7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- The question 89 is:\n",
            "\tWas there a storm headed that way?\n",
            "- The actual answer is:\n",
            "\tYes\n",
            "- The predicted answer is:\n",
            "\tyes\n",
            "\n",
            "- The question 1 is:\n",
            "\tWhat color was Cotton?\n",
            "- The actual answer is:\n",
            "\twhite\n",
            "- The predicted answer is:\n",
            "\ta white white\n",
            "\n",
            "- The question 1189 is:\n",
            "\tIs Lily old?\n",
            "- The actual answer is:\n",
            "\tno\n",
            "- The predicted answer is:\n",
            "\tyes\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_model(model, dataset_test, tokenizer, max_length=20, idx_sample=[88, 0, 1188])"
      ],
      "id": "SAPTA4X1tf_7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-grain f1 score evaluation"
      ],
      "metadata": {
        "id": "i29yX8I7trlP"
      },
      "id": "i29yX8I7trlP"
    },
    {
      "cell_type": "markdown",
      "id": "AntOxXv8C44o",
      "metadata": {
        "id": "AntOxXv8C44o"
      },
      "source": [
        "#### Compute top-5 better and worst questions\n",
        "In the following function I compute the 5 best and 5 worst answers for the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ogU00_ZAzI0F",
      "metadata": {
        "id": "ogU00_ZAzI0F"
      },
      "outputs": [],
      "source": [
        "def compute_f1_single_questions(predicted_answers: List[str], answers: List[str],\n",
        "                                metric) -> List[int]:\n",
        "    '''\n",
        "        It computes the f1 score for each single question and returns the scores.\n",
        "        Parameters:\n",
        "            - predicted_answers: list\n",
        "                The list of predicted answers (strings), that you can get from the \n",
        "                'compute_f1_score' function.\n",
        "            - answers: list\n",
        "                The list of actual answers.\n",
        "            - metric:\n",
        "                In this case a f1 squad metric is needed because we add the batches\n",
        "                with a predefined schema.\n",
        "\n",
        "        Returns:\n",
        "            - list\n",
        "                The list of f1 scores for each sample.\n",
        "    '''\n",
        "    scores = []\n",
        "\n",
        "    # Compute the f1 score for each sample\n",
        "    for pred, real in zip(predicted_answers, answers):\n",
        "        pr={'prediction_text':pred, 'id':str(0)}\n",
        "        re={'answers': {'text':[real],'answer_start':[0],},'id':str(0)}\n",
        "\n",
        "        scores.append(metric.compute(predictions=[pr], references=[re])['f1'])\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "eQ-tTXejEgBd",
      "metadata": {
        "id": "eQ-tTXejEgBd"
      },
      "outputs": [],
      "source": [
        "def compute_top_worst_k(scores, questions, answers, predictions, k=5):\n",
        "    '''\n",
        "        It computes the top and worst k questions (considering f1 score).\n",
        "    '''\n",
        "    idx_sort = np.argsort(scores)\n",
        "    # We revert the list because the best score is the last one (highest)\n",
        "    top_k = idx_sort[-k:][::-1]\n",
        "    worst_k = idx_sort[:k]\n",
        "\n",
        "    data_top = [(scores[i], questions[i], answers[i], predictions[i]) for i in top_k]\n",
        "    data_worst = [(scores[i], questions[i], answers[i], predictions[i]) for i in worst_k]\n",
        "\n",
        "    ranking_top = pd.DataFrame(data_top, columns=[\"F1 SCORE\",\"Question\",\"Answer\",\"Predicted\"])\n",
        "    ranking_worst = pd.DataFrame(data_worst, columns=[\"F1 SCORE\",\"Question\",\"Answer\",\"Predicted\"])\n",
        "    print(f\"The top five f1 scores are:\")\n",
        "    display(ranking_top)\n",
        "    print(f\"\\nThe worst five f1 scores are:\")\n",
        "    display(ranking_worst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "fL7znhif_Xro",
      "metadata": {
        "id": "fL7znhif_Xro",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "294d32fe-aec1-4b8e-98e0-045f89c41355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top five f1 scores are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   F1 SCORE                                          Question Answer Predicted\n",
              "0     100.0                             Did she kill someone?    yes       yes\n",
              "1     100.0  Did Mr. Hunter have full authority when he left?    Yes       yes\n",
              "2     100.0                             Did someone get hurt?    Yes       yes\n",
              "3     100.0                                   Was it snowing?    yes       yes\n",
              "4     100.0                              Did she talk to him?    yes       yes"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b4a7637-6692-4894-8305-e4738458893e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1 SCORE</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100.0</td>\n",
              "      <td>Did she kill someone?</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100.0</td>\n",
              "      <td>Did Mr. Hunter have full authority when he left?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100.0</td>\n",
              "      <td>Did someone get hurt?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100.0</td>\n",
              "      <td>Was it snowing?</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100.0</td>\n",
              "      <td>Did she talk to him?</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b4a7637-6692-4894-8305-e4738458893e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b4a7637-6692-4894-8305-e4738458893e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b4a7637-6692-4894-8305-e4738458893e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The worst five f1 scores are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   F1 SCORE                Question                         Answer   Predicted\n",
              "0       0.0  What color was Cotton?                          white  the United\n",
              "1       0.0          was she there?                             No  the garden\n",
              "2       0.0    Who's trruck was it?                    their mom's       a car\n",
              "3       0.0                    why?  They were going to the circus       a car\n",
              "4       0.0         What was in it?                     cool stuff       a car"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cf7fa69-0e05-449a-a390-01efa571f7b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1 SCORE</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>What color was Cotton?</td>\n",
              "      <td>white</td>\n",
              "      <td>the United</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>was she there?</td>\n",
              "      <td>No</td>\n",
              "      <td>the garden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Who's trruck was it?</td>\n",
              "      <td>their mom's</td>\n",
              "      <td>a car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>why?</td>\n",
              "      <td>They were going to the circus</td>\n",
              "      <td>a car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>What was in it?</td>\n",
              "      <td>cool stuff</td>\n",
              "      <td>a car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cf7fa69-0e05-449a-a390-01efa571f7b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9cf7fa69-0e05-449a-a390-01efa571f7b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9cf7fa69-0e05-449a-a390-01efa571f7b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "f1_scores_quest = compute_f1_single_questions(pred_answers, dataset_test['answers'], f1_metric)\n",
        "\n",
        "compute_top_worst_k(f1_scores_quest, dataset_test['questions'], dataset_test['answers'], pred_answers, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZWcxygHiJOdI",
      "metadata": {
        "id": "ZWcxygHiJOdI"
      },
      "source": [
        "#### Compute f1 by source and dialogue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "21lJXahvca8q",
      "metadata": {
        "id": "21lJXahvca8q"
      },
      "outputs": [],
      "source": [
        "# TODO: maybe it's faster if we compute all the pred and ref and then\n",
        "# we add_batch to the metric\n",
        "def compute_f1_group(sample, metric):\n",
        "    '''\n",
        "        It computes the f1 score and the sum of the questions, answers and predicted\n",
        "        answers for the samples within a same dialogue provided by a source.\n",
        "    '''\n",
        "    sumstr = []\n",
        "    for i, (ans, pr) in enumerate(zip(sample['answers'], sample['predictions'])):\n",
        "        pred = {'prediction_text':pr, 'id':str(i)}\n",
        "        ref = {'answers': {'text':[ans],'answer_start':[0]},'id':str(i)}\n",
        "        metric.add(prediction=pred, reference=ref)\n",
        "        sumstr.append(f\"Q:{sample['questions'].iloc[i]} A:{ans} P:{pr}\")\n",
        "\n",
        "    return pd.Series({'f1':metric.compute()['f1'], 'dialogue': sumstr})\n",
        "\n",
        "\n",
        "def f1_score_source_dialogue(df, predictions, metric, drop_index=None):\n",
        "    '''\n",
        "        Returns a DataFrame with 2 additional columns, one for the f1 score at\n",
        "        a dialogue level and another for the dialogue with the questions, the \n",
        "        answers and the predicted answers.\n",
        "    '''\n",
        "    assert len(predictions) == len(df), \"ERROR: predictions array has not the same length of the DataFrame\"\n",
        "    \n",
        "    new_df = df.copy()\n",
        "    new_df['predictions'] = predictions\n",
        "\n",
        "    new_df = new_df.groupby(['source','story'], sort=True) \\\n",
        "                    .apply(compute_f1_group, metric=metric)\n",
        "\n",
        "    if drop_index is not None:\n",
        "        assert isinstance(drop_index, bool), \"ERROR: drop_index needs to be a bool.\"\n",
        "        new_df = new_df.reset_index(drop=drop_index)\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "dxEsDFoXgnta",
      "metadata": {
        "id": "dxEsDFoXgnta"
      },
      "outputs": [],
      "source": [
        "df_f1 = f1_score_source_dialogue(df_final_evaluation, pred_answers, f1_metric)\n",
        "#df_f1.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "worst_5_dialogues = df_f1.groupby('source', as_index=False).apply(lambda x: x.nsmallest(5, columns=['f1']))\n",
        "display(worst_5_dialogues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kxeDgV2Mqbfy",
        "outputId": "34d2bae0-7f39-4d25-da69-5d4c13a587c1"
      },
      "id": "kxeDgV2Mqbfy",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                 f1  \\\n",
              "  source    story                                                     \n",
              "0 cnn       (CNN) -- A Russian bookmaking company is offeri...  0.0   \n",
              "            (CNN) -- FBI agents on Friday night searched th...  0.0   \n",
              "            (CNN) -- Lionel Messi is not for sale. \\n\\nThat...  0.0   \n",
              "            (CNN) -- Pablo Sandoval's record-tying three ho...  0.0   \n",
              "            (CNN)A chiseled boxer's Instagram feed shows hi...  0.0   \n",
              "1 gutenberg CHAPTER 6 \\n\\nCan piety the discord heal, Or st...  0.0   \n",
              "            CHAPTER FIFTY FIVE. \\n\\nWAITING. \\n\\nThe length...  0.0   \n",
              "            CHAPTER IV. \\n\\nLady Wallinger and Edith were t...  0.0   \n",
              "            CHAPTER VIII. \\n\\nHOSTAGE. \\n\\nThe revolution o...  0.0   \n",
              "            CHAPTER VIII. STEAD IN POSSESSION. \\n\\n\"At nigh...  0.0   \n",
              "2 mctest    Andrew waited for his granddaddy to show up. Th...  0.0   \n",
              "            As Michael put each finger on the white laces o...  0.0   \n",
              "            Hey! That isn't fair! Knights can't fly! Only w...  0.0   \n",
              "            It's finally the weekend of Halloween and I get...  0.0   \n",
              "            Lisa has a pet cat named Whiskers. Whiskers is ...  0.0   \n",
              "3 race      A couple of weeks ago, my 12-year-old daughter,...  0.0   \n",
              "            A great loss--Shirley Temple dies at 85 \\n\\nFeb...  0.0   \n",
              "            I'm Leo. There is a great artist in my family. ...  0.0   \n",
              "            Jack and James were good friends .One day,they ...  0.0   \n",
              "            John: Here's a good shop. Shall we buy mother's...  0.0   \n",
              "4 wikipedia A thorough understanding of adolescence in soci...  0.0   \n",
              "            Hanoi ( or ; , ) is the capital of the Socialis...  0.0   \n",
              "            New Haven (local /nu hevn/, noo-HAY-vn), i...  0.0   \n",
              "            Plymouth (i/plm/) is a city on the south co...  0.0   \n",
              "            RCA Records is an American record label owned b...  0.0   \n",
              "\n",
              "                                                                                                         dialogue  \n",
              "  source    story                                                                                                  \n",
              "0 cnn       (CNN) -- A Russian bookmaking company is offeri...  [Q:What did the firm do with the offer? A:decl...  \n",
              "            (CNN) -- FBI agents on Friday night searched th...  [Q:Whose house was searched? A:Gary Giordano P...  \n",
              "            (CNN) -- Lionel Messi is not for sale. \\n\\nThat...  [Q:who is not for sale A:Lionel Messi P:the fr...  \n",
              "            (CNN) -- Pablo Sandoval's record-tying three ho...  [Q:who had 3 home runs ? A:Pablo Sandoval P:th...  \n",
              "            (CNN)A chiseled boxer's Instagram feed shows hi...  [Q:Who are the two boxer featured in this arti...  \n",
              "1 gutenberg CHAPTER 6 \\n\\nCan piety the discord heal, Or st...  [Q:Who wanted a friend like her brother? A:Mrs...  \n",
              "            CHAPTER FIFTY FIVE. \\n\\nWAITING. \\n\\nThe length...  [Q:Who was excommunicated? A:Fra Girolamo P:th...  \n",
              "            CHAPTER IV. \\n\\nLady Wallinger and Edith were t...  [Q:Was someone in the morning room alone? A:no...  \n",
              "            CHAPTER VIII. \\n\\nHOSTAGE. \\n\\nThe revolution o...  [Q:What was the revolution A:Todos Santos P:th...  \n",
              "            CHAPTER VIII. STEAD IN POSSESSION. \\n\\n\"At nigh...  [Q:Who surrendered? A:the garrison of Bristol ...  \n",
              "2 mctest    Andrew waited for his granddaddy to show up. Th...  [Q:Why? A:Because they were going fishing. P:h...  \n",
              "            As Michael put each finger on the white laces o...  [Q:What sport was Michael playing? A:football ...  \n",
              "            Hey! That isn't fair! Knights can't fly! Only w...  [Q:What character is Frank playing? A:Knight P...  \n",
              "            It's finally the weekend of Halloween and I get...  [Q:How old is my brother? A:3 years old P:thre...  \n",
              "            Lisa has a pet cat named Whiskers. Whiskers is ...  [Q:Why is Lisa excited? A:Saturday, Whiskers t...  \n",
              "3 race      A couple of weeks ago, my 12-year-old daughter,...  [Q:Who threatened to take a phone? A:Ella. P:h...  \n",
              "            A great loss--Shirley Temple dies at 85 \\n\\nFeb...  [Q:Who is this news story about? A:Shirley Tem...  \n",
              "            I'm Leo. There is a great artist in my family. ...  [Q:What is in the second drawing? A:a woman P:...  \n",
              "            Jack and James were good friends .One day,they ...  [Q:What type of friends were they? A:good P:a ...  \n",
              "            John: Here's a good shop. Shall we buy mother's...  [Q:Did they go inside the shop? A:No P:yes, Q:...  \n",
              "4 wikipedia A thorough understanding of adolescence in soci...  [Q:What non-biological purpose does it have? A...  \n",
              "            Hanoi ( or ; , ) is the capital of the Socialis...  [Q:When was Hanoi first inhabited? A:3000 BC P...  \n",
              "            New Haven (local /nu hevn/, noo-HAY-vn), i...  [Q:What was it's population in 2012? A:130,741...  \n",
              "            Plymouth (i/plm/) is a city on the south co...  [Q:What grew as a commercial port during the I...  \n",
              "            RCA Records is an American record label owned b...  [Q:who are some artists currently working with...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bef40e69-2ce0-464b-8e4e-34502916a59f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>dialogue</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">cnn</th>\n",
              "      <th>(CNN) -- A Russian bookmaking company is offering to pay 100,000 euros for Paul, the prognosticating octopus who correctly predicted Spain's win in the World Cup. \\n\\n\"100,000 euros (about $129,800) was our starting price,\" Oleg Zhuravsky, co-owner of Liga Stavok -- \"Bet League\" in Russian -- told CNN. He said the offer could be increased if need be -- \"We are bookmakers, after all.\" \\n\\nPaul currently lives at the Sea Life Center in Oberhausen, Germany. Zhuravsky said a representative of the center's public relations firm has told him the offer has been received and \"they are studying it.\" \\n\\nHowever, the firm, Dederichs Reinecke and Parner, said it declined the Russian offer and that Paul will not be sold to anyone. \\n\\n\"Seriously speaking, we want the octopus for a number of purposes,\" Zhuravsky said. \"First, to see whether he can indeed effectively forecast the results of the football games. Secondly, Paul could become a good mascot, a good symbol for my bookmaking companies. And thirdly, he has an international fame like perhaps no other animal across the world does these days, and I'd love to be able to move him to Russia. \\n\\n\"Both kids and adults, I'm sure, would love to see him here,\" he said. \"We are even prepared to put him in the Moscow City Aquarium if that were the condition.\" \\n\\nHe said Paul would be given \"the best food\" and officials would let him forecast the results of the Russian domestic football tournament, \"which, I think, is a more difficult task than predicting the World Cup,\" he said. \"This would also boost the profile of the Moscow Aquarium.\"</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What did the firm do with the offer? A:decl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CNN) -- FBI agents on Friday night searched the Maryland home of the suspect in the recent disappearance of an American woman in Aruba, an agent said. \\n\\nThe search is occurring in the Gaithersburg residence of Gary Giordano, who is currently being held in an Aruban jail, FBI Special Agent Rich Wolf told CNN. \\n\\nAgents, wearing vests that said FBI and carrying empty cardboard and plastic boxes, arrived about 8:40 p.m. Friday. About 15 unmarked cars could be seen on the street, as well as a Montgomery County police vehicle. \\n\\nSupervisory Special Agent Philip Celestini, who was at the residence, declined to comment further on the search, citing the active investigation. \\n\\nAruban Solicitor General Taco Stein said earlier Friday that the suspect will appear in court Monday, where an investigating magistrate could order him held for at least eight more days, order him to remain on the island or release him outright due to a lack of evidence. \\n\\nGiordano was arrested by Aruban police on August 5, three days after Robyn Gardner was last seen near Baby Beach on the western tip of the Caribbean island. \\n\\nGiordano told authorities that he had been snorkeling with Gardner when he signaled to her to swim back, according to a statement. When he reached the beach, Gardner was nowhere to be found, Giordano allegedly said. \\n\\nThe area that Giordano led authorities to is a rocky, unsightly location that locals say is not a popular snorkeling spot. \\n\\nAlthough prosecutors have continued to identify the 50-year-old American man by his initials, GVG, they also released a photo of a man who appears to be Giordano. His attorney, Michael Lopez, also has said that his client is being held as a suspect in Gardner's death. Lopez has not returned telephone calls seeking comment.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Whose house was searched? A:Gary Giordano P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CNN) -- Lionel Messi is not for sale. \\n\\nThat was the defiant message from Barcelona's new president, who is adamant that the club's all-time leading goalscorer is going nowhere amid reports French club Paris St Germain want to sign the Argentine. \\n\\nJosep Maria Bartomeu will sit down with the four-time World Player of the Year to thrash out a new contract which will see him remain as most highly-paid at the Camp Nou. \\n\\n\"We want to sit down, without any rush, with Leo's father -- it's not something that's happening tomorrow, we have plenty of time, but we will do what we have to to ensure he's the best paid player,\" said Josep Maria Bartomeu, who assumed control at Barca after Sandro Rosell's resignation last week. \\n\\nMessi arrived at Barca in 2000 , graduating through the club's youth system before going on to establish himself as the best player on the planet. \\n\\nSince making his first team debut in 2004, Messi has helped the team win six Spanish league titles, two Spanish Cups and three European Champions League crowns. \\n\\nBlog: Is Ronaldo really the best? \\n\\nThe club's determination to keep hold of Messi will be sweet relief to Barca fans after a turbulent few weeks. \\n\\nFormer president Rosell stepped down after a Spanish judge's decision to investigate the deal which saw Neymar move to Catalonia from Brazilian team Santos last June. \\n\\nThe club initially announced the deal was worth $78 million, but the breakdown of the agreement was never revealed. \\n\\nA Barcelona member launched a case against Rosell for not disclosing the full details and the club was asked by Spanish authorities to hand over documentation, as well as accounts for the past three years.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:who is not for sale A:Lionel Messi P:the fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CNN) -- Pablo Sandoval's record-tying three home runs led the San Francisco Giants to an 8-3 victory over the Detroit Tigers in Game 1 of the World Series. \\n\\nBarry Zito gave up just one run in 5 2/3 innings to earn the win for San Francisco. He also had a run-scoring single in the fourth inning. \\n\\nTigers pitching ace Justin Verlander only managed to go four innings, allowing five runs on six hits. \\n\\nSandoval, who had 12 home runs during the regular season, hit a solo home run in the first and a two-run shot in the third off Verlander. In the fifth, he added another home run off Al Alburquerque. He has six home runs in the postseason. \\n\\n\"In this situation you're going to face the best. For me I just go in there and don't thinking too much or try to do too much, get a pitch you can hit, take advantage of the mistakes he be making. That's a part of my game.\" Sandoval said. \\n\\nHis manager said Sandoval has been swinging the bat well for weeks. \\n\\n\"He's been locked in for a while, and the home runs, really where he hit them, too, it's not easy to hit them where he hit them,\" Giants skipper Bruce Bochy said. \\n\\nThree other players have homered three times in one World Series game. \\n\\nBabe Ruth did it twice, and Reggie Jackson also achieved the feat. Last year, St. Louis Cardinals slugger Albert Pujols had three home runs in Game 3.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:who had 3 home runs ? A:Pablo Sandoval P:th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CNN)A chiseled boxer's Instagram feed shows him making constant references to the Bible and enjoying gospel singing with his wife. \\n\\nAnother features his formidable opponent counting stacks of money, hanging out in strip clubs, and flashing diamond watches and Ferraris. \\n\\nWelcome to the world of boxing promotion, circa 2015. \\n\\nAmerican Floyd Mayweather and Filipino Manny Pacquiao are set to officially announce their heavily anticipated boxing match at a press conference in Los Angeles Wednesday. \\n\\nWith the combined purse for the May 2 bout in Las Vegas reported to touch $300 million pending viewership numbers, the incentives to self-promote could not be higher. \\n\\n\"Nowadays you have to be on social media to launch the fight and to build hype,\" says boxing promoter Nisse Sauerland, CEO of Team Sauerland. \"It couldn't be done without it.\" \\n\\nThirty-eight year old Mayweather (47-0, 26 knockouts), who favors the moniker \"The Money Man\" or \"TBE\" (The Best Ever), boasts nearly five million Instagram followers, 5.65 million followers on Twitter and 9.2 million Facebook likes. \\n\\nHe famously confirmed the fight via Shots, a photo sharing social media application that he's invested in, and displays links to his clothing brand, The Money Team, on all his accounts. \\n\\nAlong with professing to the be the best fighter of all time, he could also stake a claim to be one of the greatest social media users in sports. \\n\\n\"I think they're both playing their roles,\" says Sauerland, who promotes over 45 boxers. \"You've got the bad guy and the good guy, really. You've got the guy who throws the money around (Mayweather), that's his image, and Pacquiao, he's the hope of a nation.\"</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Who are the two boxer featured in this arti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">gutenberg</th>\n",
              "      <th>CHAPTER 6 \\n\\nCan piety the discord heal, Or stanch the death-feud's enmity? --Scott \\n\\nIt must not be supposed that such a history of Guy's mind was expressed by himself, or understood by Mrs. Edmonstone; but she saw enough to guess at his character, perceive the sort of guidance he needed, and be doubly interested in him. Much did she wish he could have such a friend as her brother would have been, and hope that nothing would prevent a friendship with her nephew. \\n\\nThe present question about the horse was, she thought, unfortunate, since, though Guy had exercised great self-denial, it was no wonder Philip was annoyed. Mr. Edmonstone's vexation was soon over. As soon as she had persuaded him that there had been no offence, he strove to say with a good grace, that it was very proper, and told Guy he would be a thorough book-worm and tremendous scholar, which Guy took as an excellent joke. \\n\\nPhilip had made up his mind to be forbearing, and to say no more about it. Laura thought this a pity, as they could thus never come to an understanding; but when she hinted it, he wore such a dignified air of not being offended, that she was much ashamed of having tried to direct one so much better able to judge. On his side Guy had no idea the trouble he had caused; so, after bestowing his thanks in a gay, off-hand way, which Philip thought the worst feature of the case, he did his best to bring Hecuba back into his mind, drive the hunters out of it, and appease the much-aggrieved William of Deloraine.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Who wanted a friend like her brother? A:Mrs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER FIFTY FIVE. \\n\\nWAITING. \\n\\nThe lengthening sunny days went on without bringing either what Romola most desired or what she most dreaded. They brought no sign from Baldassarre, and, in spite of special watch on the part of the Government, no revelation of the suspected conspiracy. But they brought other things which touched her closely, and bridged the phantom-crowded space of anxiety with active sympathy in immediate trial. They brought the spreading Plague and the Excommunication of Savonarola. \\n\\nBoth these events tended to arrest her incipient alienation from the Frate, and to rivet again her attachment to the man who had opened to her the new life of duty, and who seemed now to be worsted in the fight for principle against profligacy. For Romola could not carry from day to day into the abodes of pestilence and misery the sublime excitement of a gladness that, since such anguish existed, she too existed to make some of the anguish less bitter, without remembering that she owed this transcendent moral life to Fra Girolamo. She could not witness the silencing and excommunication of a man whose distinction from the great mass of the clergy lay, not in any heretical belief, not in his superstitions, but in the energy with which he sought to make the Christian life a reality, without feeling herself drawn strongly to his side. \\n\\nFar on in the hot days of June the Excommunication, for some weeks arrived from Rome, was solemnly published in the Duomo. Romola went to witness the scene, that the resistance it inspired might invigorate that sympathy with Savonarola which was one source of her strength. It was in memorable contrast with the scene she had been accustomed to witness there.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Who was excommunicated? A:Fra Girolamo P:th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER IV. \\n\\nLady Wallinger and Edith were together in the morning room of Hellingsley, the morrow after the arrival of Oswald. Edith was arranging flowers in a vase, while her aunt was embroidering a Spanish peasant in correct costume. The daughter of Millbank looked as bright and fragrant as the fair creations that surrounded her. Beautiful to watch her as she arranged their forms and composed their groups; to mark her eye glance with gratification at some happy combination of colour, or to listen to her delight as they wafted to her in gratitude their perfume. Oswald and Sir Joseph were surveying the stables; Mr. Millbank, who had been daily expected for the last week from the factories, had not yet arrived. \\n\\n'I must say he gained my heart from the first,' said Lady Wallinger. \\n\\n'I wish the gardener would send us more roses,' said Edith. \\n\\n'He is so very superior to any young man I ever met,' continued Lady Wallinger. \\n\\n'I think we must have this vase entirely of roses; don't you think so, aunt?' inquired her niece. \\n\\n'I am fond of roses,' said Lady Wallinger. 'What beautiful bouquets Mr. Coningsby gave us at Paris, Edith!' \\n\\n'Beautiful!' \\n\\n'I must say, I was very happy when I met Mr. Coningsby again at Cambridge,' said Lady Wallinger. 'It gave me much greater pleasure than seeing any of the colleges.' \\n\\n'How delighted Oswald seems at having Mr. Coningsby for a companion again!' said Edith. \\n\\n'And very naturally,' said Lady Wallinger. 'Oswald ought to deem himself fortunate in having such a friend. I am sure the kindness of Mr. Coningsby when we met him at Cambridge is what I never shall forget. But he always was my favourite from the first time I saw him at Paris. Do you know, Edith, I liked him best of all your admirers.'</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Was someone in the morning room alone? A:no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER VIII. \\n\\nHOSTAGE. \\n\\nThe revolution of Todos Santos had to all appearances been effected as peacefully as the gentle Liberator of Quinquinambo could have wished. Two pronunciamientos, rudely printed and posted in the Plaza, and saluted by the fickle garrison of one hundred men, who had, however, immediately reappointed their old commander as Generalissimo under the new regime, seemed to leave nothing to be desired. A surging mob of vacant and wondering peons, bearing a singular resemblance to the wild cattle and horses which intermingled with them in blind and unceasing movement across the Plaza and up the hilly street, and seemingly as incapable of self-government, were alternately dispersed and stampeded or allowed to gather again as occasion required. Some of these heterogeneous bands were afterwards found--the revolution accomplished--gazing stupidly on the sea, or ruminating in bovine wantonness on the glacis before the Presidio. \\n\\nEleanor Keene, who with her countrywomen had been hurried to the refuge of the Mission, was more disturbed and excited at the prospect of meeting Hurlstone again than by any terror of the insurrection. But Hurlstone was not there, and Father Esteban received her with a coldness she could not attribute entirely to her countrymen's supposed sympathy with the insurgents. When Richard Keene, who would not leave his sister until he had seen her safe under the Mission walls, ventured at her suggestion to ask after the American recluse, Father Esteban replied dryly that, being a Christian gentleman, Hurlstone was the only one who had the boldness to seek out the American filibuster Perkins, on his own ship, and remonstrate with him for his unholy crusade. For the old priest had already become aware of Hurlstone's blunder, and he hated Eleanor as the primary cause of the trouble. But for her, Diego would be still with him in this emergency.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What was the revolution A:Todos Santos P:th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER VIII. STEAD IN POSSESSION. \\n\\n\"At night returning, every labour sped, He sits him down, the monarch of a shed.\" GOLDSMITH. \\n\\nAnother day made it certain that the garrison of Bristol had surrendered to the besiegers. A few shots were heard, but they were only fired in rejoicing by the Royalists, and while Steadfast was studying his barley field, already silvered over by its long beards, and wondering how soon it would be ripe, and how he should get it cut and stacked, his name was shouted out, and he saw Tom Oates and all the rest of the boys scampering down the lane. \\n\\n\"Come along, Stead Kenton, come on and see, the Parliament soldiers come out and go by.\" \\n\\nPoor Steadfast had not much heart for watching soldiers, but it struck him that he might see or hear something of Jephthah, so he came with the other boys to the bank, where from behind a hedge they could look down at the ranks of soldiers as they marched along, five abreast, the road was not wide enough to hold more. They had been allowed to keep their weapons, so the officers had their swords, and the men carried their musquets. Most of them looked dull and dispirited, and the officers had very gloomy, displeased faces. In fact, they were very angry with their commander, Colonel Fiennes, for having surrendered so easily, and he was afterwards brought to a court-martial for having done so. \\n\\nStead did not understand this, he thought only of looking under each steel cap or tall, slouching hat for Jephthah. Several times a youthful, slender figure raised his hopes, and disappointed him, and he began to wonder whether Jeph could have after all stayed behind in the town, or if he could have been hurt and was ill there.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Who surrendered? A:the garrison of Bristol ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">mctest</th>\n",
              "      <th>Andrew waited for his granddaddy to show up. They were going fishing. His mom had packed them a lunch. She had made Peanut Butter and Jelly Sandwiches. She also packed a bottle of nice cool water to drink. Andrew had wanted something else for lunch. He wanted chicken or cold cuts or left over meat loaf, but his mom sent Peanut Butter and Jelly sandwiches. The best way to get to the river was along the path. When the path ended, they needed to go through the bushes to the river. On some days they would think about going another way. They could go over the bridge, or through the back of the house or through Uncle Tom's yard. Today they took the path to the river. Andrew found some animal poop along the path. He asked his Grandpa what kind of animal poop he had found. He wanted to know if it was a lion, a tiger or a bear that had made the poop. Grandpa pointed in the bushes. Andrew saw a small black and white animal looking at him with big eyes. Andrew knew that he had was looking at a raccoon. He was sure that the raccoon had made the poop. When Andrew and Grandpa got to the river they put their fishing poles into the water. Andrew caught his first fish right away. He caught a second fish before lunch. He got hungry and had his Peanut Butter and Jelly sandwich and cool water. He saw that Grandpa had fallen asleep. After eating his lunch, Andrew caught three more fish before he woke up his grandpa. When Andrew and Grandpa got back home they gave all the fish they had caught to Andrew's mother, so she could make a good dinner.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Why? A:Because they were going fishing. P:h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>As Michael put each finger on the white laces of the football like his dad had shown him he thought about his school trip to the zoo tomorrow. He could not wait to get to the zoo and most of all could not wait to see his favorite animal, the lion. Aiming the football at the tire swing that hung in his back yard, he remembered the second thing his dad had taught him about throwing a football which was making sure his shoulder and the football were in a straight line before he threw it. He watched the football sail toward the tire, right as his mom called him in for dinner. His mom had made his favorite food, hotdogs. He sat in the kitchen and watched as ketchup fell on to his plate as he ate his hotdog. His mom told him that in order to get his after dinner treat he would have to eat his corn, carrots, and drink all of his milk too. \\n\\nThat night as his mom tucked him in to bed he starred out the window and wondered if the lions at the zoo were looking up at the moon too. Michael, wondered if his best friends Joe, Nick, and Ryan were as excited as he was about going to the zoo the next day. He closed his eyes and went to sleep. \\n\\nThe next day he hopped from one foot to the other as his class lined up to get on the bus that would take him to the zoo. On the bus he sat with Ryan. The bus driver started the engine and turned the big steering wheel leading them out on to the road. Finally, at the zoo Michael began to imagine how cool it would be to finally get to see the lion cage. First his class went to see the monkeys and then headed over to see the long necked giraffes. As their teacher announced that they would then be going to see the elephants, we wondered if he would ever get to see the lions. Finally after learning about the elephants it was time to see the lions. The lion stood on a huge rock and swung its long tail from side to side. The lion licked his lips with its long pink tongue and Michael wondered if it was thinking about having a class full of kids for its lunch.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What sport was Michael playing? A:football ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hey! That isn't fair! Knights can't fly! Only wizards like me can! And maybe also witches. Bobby yelled. \\n\\n\"Yes! They can, too!\" Frank said, \"They're the most powerful and you can't stop me from flying!\" \\n\\n\"Well, if you fly, then I can fight with a sword, too. It's only fair,\" Bobby said back. \\n\\n\"No! They can't! They aren't even strong enough to pick up a sword. They can't even pick up a knife, they're so weak! I don't even know what you're talking about. You're crazy, aren't you?\" Frank pointed his finger at Bobby and ran at him with the sword made out of cardboard. \\n\\nBobby jumped out of the way as quickly as he could! Bobby then pointed a finger at Frank. \"FREEZE!\" \\n\\nFrank stopped in place. \"Hey, you can't use the freeze spell. How can I fight you if I can't move? I'm going to tell mom.\" \\n\\n\"I can use any spell I want! I can use Freeze, Trap, and Fly! I can do any of them! I'm also telling mom that you think you can fly and you can't. You're a stupid knight with no brains. I have all the brains here.\" Bobby crossed his arms over his chest and stomped a foot on the ground. \\n\\n\"You take that back! I'm the smartest knight there is and I'll get you any day!\" Suddenly, Frank pulled Bobby to the ground. \"Take it back right now!\" \\n\\n\"BOYS! What's all the noise?\" Mom asked. \\n\\n\"Bobby called me stupid!\" Frank yelled. \\n\\n\"Frank is trying to fly!\" Bobby cried. \\n\\n\"Oh boy.\" Mom laughed.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What character is Frank playing? A:Knight P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>It's finally the weekend of Halloween and I get to dress up in my lion costume. Halloween is my favorite holiday because I really like candy and love dressing up. Last year I was a ghost, but this year I am a lion. My little brother is dressed like a dinosaur and he keeps chewing on everything. He is only 3 years old so I guess that is okay. His name is Todd and his favorite holiday is his birthday but I don't think he knows much about any of them. My dad loves Christmas and my Mom really likes Thanksgiving. But I love Halloween. We have to wait for my dad to come home from work so we can go out and trick-or-treat. While we are waiting my mommy cooks us dinner. She wants us to eat good food before we spoil our dinner with all the candy we are going to get. I can't wait to go to my friend Kevin's house. His parents give the best candy and give me extra since Kevin is my friend. I think Kevin said he was going to dress up like a pirate but I don't remember. I don't think pirates are very cool, but I didn't tell Kevin that. I think I hear my dad coming up the stairs. Tonight is going to be the best Halloween ever.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:How old is my brother? A:3 years old P:thre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lisa has a pet cat named Whiskers. Whiskers is black with a white spot on her chest. Whiskers also has white paws that look like little white mittens. \\n\\nWhiskers likes to sleep in the sun on her favorite chair. Whiskers also likes to drink creamy milk. \\n\\nLisa is excited because on Saturday, Whiskers turns two years old. \\n\\nAfter school on Friday, Lisa rushes to the pet store. She wants to buy Whiskers' birthday presents. Last year, she gave Whiskers a play mouse and a blue feather. \\n\\nFor this birthday, Lisa is going to give Whiskers a red ball of yarn and a bowl with a picture of a cat on the side. The picture is of a black cat. It looks a lot like Whiskers.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Why is Lisa excited? A:Saturday, Whiskers t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">race</th>\n",
              "      <th>A couple of weeks ago, my 12-year-old daughter, Ella threatened to take my phone and break it. \"At night you'll always have your phone out and break you'll just type,\" Ella says. \"I'm ready to go to bed, and try to get you to read stories for me and you're just standing there reading your texts and texting other people,\" she adds. I came to realize that I was ignoring her as a father. \\n\\nElla isn't the only kid who feels this way about her parent's relationship with devices. Catherine Steiner-Adair, a psychologist at Harvard, wrote The Big Disconnect: Protecting Childhood and Family Relationships in the Digital Age. For her book, Steiner-Adair interviewed more than 1,000 kids from the ages of 4 to 18. She talked to hundreds of teachers and parents. \\n\\nOne of the many things that knocked my socks off, \" she says, \"was the consistency with which children -- whether they were 4 or 8 or 18 or 24-- talked about feeling exhausted and frustrated or mad trying to get their parents' attention, competing with computer screens or iPhone screens or any kind of technology.\" \\n\\nA couple of years ago, my daughter got a laptop for school. And because she was becoming more independent, we got her a phone. We set up rules for when she could use the device and when she'd need to put it away. We created a charging station, outside her bedroom, where she had to plug in these devices every night. Basically -- except for homework-- she has to put it all away when she comes home. \\n\\nSteiner-Adair says most adults don't set up similar limits in their own lives. \"We've lost the boundaries that protect work and family life,'' she says. \"So it is very hard to manage yourself and be present in the moments your children need you.'' \\n\\nAfter my daughter's little intervention ,I made myself a promise to create my own charging station. To plug my phone in-- somewhere faraway -- when I am done working for the day. I've been trying to leave it there untouched for most of the weekend</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Who threatened to take a phone? A:Ella. P:h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A great loss--Shirley Temple dies at 85 \\n\\nFebruary 12,2014 \\n\\nBYDERRIKJ.LANG ,Associated Press \\n\\nShirley Temple Black, who died on February 10that age 85, wasn't just a child star. She was THE child star--the sweet little girl whose shining smile helped _ some of the darkest days the US has known during the Great Depression. \\n\\nIt's hard today to imagine the super star Shirley was once \"America's Little Darling\". She sang and danced her way to the top of the box office in such films as Bright Eyes, Curly Top and Heidi. By 1940, she had appeared in 43 films. Temple teamed with Bill Robison in four movies, and their dance on the stairs in The Little Colonel is still a legendary film moment. \\n\\nIn the 1930s, her name on a movie introduction assured a packed house. She inspired dolls, dresses, dishes--even a drink (alcohol-free, of course). \\n\\nUS President Franklin D. Roosevelt once famously said that \"as long as our country has Shirley Temple, we will be all right.'' \\n\\nUnlike so many of today's child stars, Temple didn't end up with her name appearing across the headlines for bad behaviors. Instead of getting her photos on front pages or struggling with drugs and alcohol, Temple went on to a second career in diplomacy , including presidential appointments as ambassador to Ghana. \\n\\nShe surprised a lot of people who doubted her with her grace, knowledge and eagerness to serve. In fact, her career in public service (20 years) was longer than her career in movies (19). The role she valued most, however, was as wife, mother, grandmother and great-grandmother. \\n\\nThe world has lost a treasured Hollywood legend. But her movies will allow that little dynamic figure to continue charming audiences for a very long time.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Who is this news story about? A:Shirley Tem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I'm Leo. There is a great artist in my family. She is Lisa. Lisa likes drawing a lot. Here are her three drawings. There is an animal in the first drawing. It has two big eyes, a big mouth and two small ears. It has long arms and long legs. It is black and white. There are some apples in its hands. It looks very happy. What is it? I don't know, but Lisa says it is a panda. There is a woman in the second drawing. She is thin. She has straight blonde hair, a small mouth, a big nose and two big eyes. She looks angry. Who is she? Lisa says she is our mom. But Mom has curly blonde hair, small eyes and a small nose. There is an animal in the third drawing, too. Its head is an apple. Its hair and tail are leaves. It has a long mouth, and _ is a banana. Its two legs are carrots. What is it? Lisa says it is a horse, but it doesn't look like a horse. Lisa is really a great artist, isn't she? .</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What is in the second drawing? A:a woman P:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jack and James were good friends .One day,they were walking through the desert .During the journey they had a big fight,and Jack hit james in the face.James felt hurt,but he didn't say anything.Instead( ),he wrote in the sand:Today my best friend hit me in the face. They kept on walking until they found an oasis .They decided to get some water there .Suddenly James had trouble in the water,he fell into the mire and was in danger.Jack saved him at once.When he felt Ok,he wrote on a stone:Today my best friend saved my life. \"After I hurt you ,you wrote in the sand, and now you wrote on the stone.Why?\"asked Jack.\"When someone hurts us,we should write it down in the sand so that the wind of forgiveness can blow it away.But when someone does anything good for us,we must write it down on the stone,so no wind can blow it away.\" Since then ,the two friends have never fought with each other again. Hatred can bring you nothing but unhappiness .If you don't forgive others,you are making trouble for yourself.Keep a peaceful heart all the time and remember to be always thankful to those who ahve helped you!</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What type of friends were they? A:good P:a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>John: Here's a good shop. Shall we buy mother's birthday present here? Mary: Yes, that's a good idea. Shall we go inside? Tom: No. Let's look in the window. Shall we buy her a sweater? Anne: Er, no. It'll soon be summer. Let's buy her a blouse to wear. There's a nice one in the window. John: No, she has two blouses. Let's buy a ring. Mary: Oh, no! They're diamond rings. Look at the price. The cheapest is $15. John: A real diamond ring is at least $500.They only look like diamonds. Tom: Shall we buy a table? It's only $15. Anne: It doesn't look good, just like a big box. Mum likes chairs. Tom: But they haven't any here. Mary: What about a pen? So cheap! Only $10. John: She has a lot of pens and pencils. All of them are new. Tom: Oh, look here. These flowers are beautiful. Mary: They aren't real and will never die. John: And they're the cheapest of all these things. Yes, let's buy them. Anne: All right.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:Did they go inside the shop? A:No P:yes, Q:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">wikipedia</th>\n",
              "      <th>A thorough understanding of adolescence in society depends on information from various perspectives, including psychology, biology, history, sociology, education, and anthropology. Within all of these perspectives, adolescence is viewed as a transitional period between childhood and adulthood, whose cultural purpose is the preparation of children for adult roles. It is a period of multiple transitions involving education, training, employment and unemployment, as well as transitions from one living circumstance to another. \\n\\nPuberty occurs through a long process and begins with a surge in hormone production, which in turn causes a number of physical changes. It is the stage of life characterized by the appearance and development of secondary sex characteristics (for example, a deeper voice and larger adam's apple in boys, and development of breasts and more curved and prominent hips in girls) and a strong shift in hormonal balance towards an adult state. This is triggered by the pituitary gland, which secretes a surge of hormonal agents into the blood stream, initiating a chain reaction to occur. The male and female gonads are subsequently activated, which puts them into a state of rapid growth and development; the triggered gonads now commence the mass production of the necessary chemicals. The testes primarily release testosterone, and the ovaries predominantly dispense estrogen. The production of these hormones increases gradually until sexual maturation is met. Some boys may develop gynecomastia due to an imbalance of sex hormones, tissue responsiveness or obesity.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What non-biological purpose does it have? A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hanoi ( or ; , ) is the capital of the Socialist Republic of Vietnam and the country's second largest city by population. Its population in 2009 was estimated at 2.6 million for urban districts and 7 million for the metropolitan jurisdiction. The population in 2015 was estimated at 7.7 million people. From 1010 until 1802, it was the most important political centre of Vietnam. It was eclipsed by Hu, the imperial capital of Vietnam during the Nguyn Dynasty (18021945), but Hanoi served as the capital of French Indochina from 1902 to 1954. From 1954 to 1976, it was the capital of North Vietnam, and it became the capital of a reunified Vietnam in 1976, after the North's victory in the Vietnam War. \\n\\nThe city lies on the right bank of the Red River. Hanoi is north of Ho Chi Minh City and west of Hai Phong city. \\n\\nOctober 2010 officially marked 1000 years since the establishment of the city. The Hanoi Ceramic Mosaic Mural is a 4km ceramic mosaic mural created to mark the occasion. \\n\\nHanoi (, \"inside (the) river\") has had many official and unofficial names throughout history. Hanoi has been inhabited since at least 3000 BC. The C Loa Citadel in Dong Anh district served as the capital of the u Lc kingdom founded by the Shu emigrant Thc Phn after his 258 BC conquest of the native Vn Lang.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:When was Hanoi first inhabited? A:3000 BC P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>New Haven (local /nu hevn/, noo-HAY-vn), in the U.S. state of Connecticut, is the principal municipality in Greater New Haven, which had a total population of 862,477 in 2010. It is located on New Haven Harbor on the northern shore of the Long Island Sound in New Haven County, Connecticut, which in turn comprises the outer limits of the New York metropolitan area. It is the second-largest city in Connecticut (after Bridgeport), with a population of 129,779 people as of the 2010 United States Census. According to a census of 1 July 2012, by the Census Bureau, the city had a population of 130,741. \\n\\nIn 1637 a small party of Puritans reconnoitered the New Haven harbor area and wintered over. In April 1638, the main party of five hundred Puritans who left the Massachusetts Bay Colony under the leadership of the Reverend John Davenport and the London merchant Theophilus Eaton sailed into the harbor. These settlers were hoping to establish a (in their mind) better theological community, with the government more closely linked to the church than the one they left in Massachusetts and sought to take advantage of the excellent port capabilities of the harbor. The Quinnipiacs, who were under attack by neighboring Pequots, sold their land to the settlers in return for protection.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What was it's population in 2012? A:130,741...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Plymouth (i/plm/) is a city on the south coast of Devon, England, about 37 miles (60 km) south-west of Exeter and 190 miles (310 km) west-south-west of London, between the mouths of the rivers Plym to the east and Tamar to the west where they join Plymouth Sound to form the boundary with Cornwall. \\n\\nPlymouth's early history extends to the Bronze Age, when a first settlement emerged at Mount Batten. This settlement continued as a trading post for the Roman Empire, until it was surpassed by the more prosperous village of Sutton, now called Plymouth. In 1620, the Pilgrim Fathers departed Plymouth for the New World and established Plymouth Colony  the second English settlement in what is now the United States of America. During the English Civil War the town was held by the Parliamentarians and was besieged between 1642 and 1646. \\n\\nThroughout the Industrial Revolution, Plymouth grew as a commercial shipping port, handling imports and passengers from the Americas, and exporting local minerals (tin, copper, lime, china clay and arsenic) while the neighbouring town of Devonport became a strategic Royal Naval shipbuilding and dockyard town. In 1914 three neighbouring independent towns, viz., the county borough of Plymouth, the county borough of Devonport, and the urban district of East Stonehouse were merged to form a single County Borough. The combined town took the name of Plymouth which, in 1928, achieved city status. The city's naval importance later led to its targeting and partial destruction during World War II, an act known as the Plymouth Blitz. After the war the city centre was completely rebuilt and subsequent expansion led to the incorporation of Plympton and Plymstock along with other outlying suburbs in 1967.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:What grew as a commercial port during the I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RCA Records is an American record label owned by Sony Music, a subsidiary of Sony Corporation of America. It is one of SME's three flagship record labels, alongside Columbia Records and Epic Records. The label has released multiple genres of music, including pop, rock, hip hop, electronic, R&amp;B, blues, jazz, and country. The company's name is derived from the initials of the label's former parent company, the Radio Corporation of America (RCA). It is the second oldest recording company in US history, after sister label Columbia Records. RCA's Canadian unit (formerly Berliner Gramophone Canada) is Sony's oldest label in Canada. It was one of only two Canadian record companies to survive the Great Depression. \\n\\nArtists currently signed to RCA Records include Britney Spears, Shakira, Christina Aguilera, Miley Cyrus, Justin Timberlake, Alicia Keys, Usher, Charlie Wilson, R. Kelly, Enrique Iglesias, Foo Fighters, Kings of Leon, Kesha, Chris Brown, D'Angelo, Pink, Walk the Moon, Pitbull and Zayn. \\n\\nIn 1929, the Radio Corporation of America (RCA) purchased the Victor Talking Machine Company, then the world's largest manufacturer of phonographs (including the famous \"Victrola\") and phonograph records (in British English, \"gramophone records\"). The company then became RCA Victor but retained use of the Victor Records name on their labels until the beginning of 1946 when the labels were finally switched over to RCA Victor. With Victor, RCA acquired New World rights to the famous Nipper \"His Master's Voice\" trademark; in Shanghai, China, RCA Victor was the main competitor with Baak Doi (EMI). Singer Carmen Miranda was signed to RCA Victor Brazilian branch, in 1929 to 1935, when she was still only known in Brazil.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[Q:who are some artists currently working with...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bef40e69-2ce0-464b-8e4e-34502916a59f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bef40e69-2ce0-464b-8e4e-34502916a59f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bef40e69-2ce0-464b-8e4e-34502916a59f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we observe more in the details one of the worst dialogues we can notice that all the predicted answers are wrong."
      ],
      "metadata": {
        "id": "FoNx_mbIuwoI"
      },
      "id": "FoNx_mbIuwoI"
    },
    {
      "cell_type": "code",
      "source": [
        "worst_5_dialogues.reset_index(drop=True)['dialogue'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeH3FZHqs-on",
        "outputId": "6d554175-5273-47dd-a3f8-482bbf9e414e"
      },
      "id": "FeH3FZHqs-on",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Q:What did the firm do with the offer? A:declined it P:he was a lawyer',\n",
              " 'Q:What is Paul going to be given? A:tyhe best food P:a new - based - based - based - based - - based - - based - -',\n",
              " 'Q:What will he forecast? A:the Russioan domestic football tournament P:a number of a number of a number of a number of a number of a number of',\n",
              " 'Q:What is this prediction harder than? A:the world cup P:it is a small number of a number of a number of a number of a number of',\n",
              " 'Q:And what will benefit from his arrival? A:the Moscow Aquarium P:a lot of money',\n",
              " 'Q:Who is being interviewed? A:Oleg Zhuravsky P:the president',\n",
              " 'Q:What is his job? A:co-owner of Liga Stavok -- \"Bet League\" in Russian P:a former former president',\n",
              " 'Q:Who is he speaking with? A:CNN P:the president',\n",
              " 'Q:How much was his offer? A:\"100,000 euros (about $129,800) P:$ 1, 000',\n",
              " 'Q:Where would Paul live? A:Moscow City Aquarium P:the university of california',\n",
              " 'Q:Where is Paul now? A:Sea Life Center in Oberhausen, Germany P:the university of china',\n",
              " 'Q:What is the name of the PR company? A:Dederichs Reinecke and Parne P:the \" \"',\n",
              " 'Q:What did the PR team do? A:declined the offer P:he was a professional player',\n",
              " 'Q:Will Paul be sold? A:no P:yes',\n",
              " 'Q:What does Bet League do? A:bookmaking P:a game',\n",
              " 'Q:What is Paul? A:an octopus P:a chinese chinese',\n",
              " 'Q:What task would Paul do in Russia? A:to forecast football games, and act as a mascot fot the bookmaker P:a computer computer',\n",
              " 'Q:What did Paul do to get people interested in him? A:predicted spain would win the world cup P:he was a lawyer',\n",
              " 'Q:Where is the Sea Life Center? A:Oberhausen, Germany. P:the city of the city',\n",
              " 'Q:Who is the most famous animal right now? A:Paul P:the president',\n",
              " 'Q:Who would be excited to see Paul? A:kids and adults P:the president',\n",
              " 'Q:What is the hardest task? A:forecast the Russian domestic football tournament, P:a computer computer']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_5_dialogues = df_f1.groupby('source', as_index=False).apply(lambda x: x.nlargest(5, columns=['f1']))\n",
        "display(best_5_dialogues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-lCmaN0B62It",
        "outputId": "49693e33-37e3-431d-de36-6a0a684261b2"
      },
      "id": "-lCmaN0B62It",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                       f1  \\\n",
              "  source    story                                                           \n",
              "0 cnn       Asuncion, Paraguay (CNN) -- Paraguay installed ...  41.250000   \n",
              "            (CNN) -- A high-speed car accident in Florida h...  36.000000   \n",
              "            (CNN) -- The United States is deeply concerned ...  35.000000   \n",
              "            NEW YORK (CNN) -- Natasha Richardson, a film st...  33.869048   \n",
              "            Paris (CNN) -- French officials Tuesday condemn...  32.000000   \n",
              "1 gutenberg CHAPTER XX THE FRIEND \\n\\n\\n\\nLess than half an...  42.857143   \n",
              "            Chapter 17: The Battle Of Moncontor. \\n\\nWhen P...  42.000000   \n",
              "            CHAPTER VII \\n\\nThe Beginning of Troubles \\n\\nL...  40.000000   \n",
              "            CHAPTER XIV \\n\\nTHE CURE \\n\\nIt was noon when H...  33.684211   \n",
              "            CHAPTER LXIV. \\n\\n\"Questa montagna e tale, Che ...  31.790123   \n",
              "2 mctest    Jessica went to sit in her rocking chair. Today...  47.991071   \n",
              "            Greta ran to the corner with her older brother ...  45.454545   \n",
              "            Jamie and his friends love playing baseball. Th...  42.857143   \n",
              "            Julia gets an allowance from her parents every ...  40.909091   \n",
              "            On a snowy winter morning, the brown-haired lad...  40.000000   \n",
              "3 race      \"Everything happens for the best,\" my mother sa...  48.684211   \n",
              "            ChiChi weighs only 13 pounds. \"He's so tiny,I c...  43.609023   \n",
              "            GERALD Christian is in Grade 8 at Ridge Road Mi...  43.518519   \n",
              "            A famous building in New York City is turning 1...  36.224490   \n",
              "            Writing articles about films for The Front Page...  35.802469   \n",
              "4 wikipedia Since 1901, the Nobel Prize in Literature () ha...  42.907268   \n",
              "            Las Vegas (, Spanish for \"The Meadows\"), offici...  36.363636   \n",
              "            Bath ( or ) is the largest city in the ceremoni...  36.134454   \n",
              "            A gene is a locus (or region) of DNA that encod...  33.333333   \n",
              "            A National Olympic Committee (NOC) is a nationa...  29.411765   \n",
              "\n",
              "                                                                                                         dialogue  \n",
              "  source    story                                                                                                  \n",
              "0 cnn       Asuncion, Paraguay (CNN) -- Paraguay installed ...  [Q:who made the announcement, the office of th...  \n",
              "            (CNN) -- A high-speed car accident in Florida h...  [Q:Where did this accident occur? A:Florida P:...  \n",
              "            (CNN) -- The United States is deeply concerned ...  [Q:Who was reportedly beaten before being depo...  \n",
              "            NEW YORK (CNN) -- Natasha Richardson, a film st...  [Q:How did Natasha die? A:She  fell on a begin...  \n",
              "            Paris (CNN) -- French officials Tuesday condemn...  [Q:Which official condemned the airstrike? A:F...  \n",
              "1 gutenberg CHAPTER XX THE FRIEND \\n\\n\\n\\nLess than half an...  [Q:Where was Marguerite? A:inside her coach P:...  \n",
              "            Chapter 17: The Battle Of Moncontor. \\n\\nWhen P...  [Q:Who was eating? A:Philip P:the king, Q:Did ...  \n",
              "            CHAPTER VII \\n\\nThe Beginning of Troubles \\n\\nL...  [Q:Would people claim bernard wasn't in love? ...  \n",
              "            CHAPTER XIV \\n\\nTHE CURE \\n\\nIt was noon when H...  [Q:Is it about a disease? A:Yes P:yes, Q:What ...  \n",
              "            CHAPTER LXIV. \\n\\n\"Questa montagna e tale, Che ...  [Q:Who cries out? A:Gwendolen P:her husband, Q...  \n",
              "2 mctest    Jessica went to sit in her rocking chair. Today...  [Q:How old would she be? A:80 P:three, Q:Did s...  \n",
              "            Greta ran to the corner with her older brother ...  [Q:Did the ice cream truck start to leave? A:Y...  \n",
              "            Jamie and his friends love playing baseball. Th...  [Q:where does Jamie play every morning? A:the ...  \n",
              "            Julia gets an allowance from her parents every ...  [Q:did ultimately Julia get her toy A:no P:yes...  \n",
              "            On a snowy winter morning, the brown-haired lad...  [Q:Who seen a squirrel? A:the lady P:the dog, ...  \n",
              "3 race      \"Everything happens for the best,\" my mother sa...  [Q:Is the narrator of the story known? A:no P:...  \n",
              "            ChiChi weighs only 13 pounds. \"He's so tiny,I c...  [Q:Is ChiChi a person? A:no P:yes, Q:What is h...  \n",
              "            GERALD Christian is in Grade 8 at Ridge Road Mi...  [Q:why did michael jordan donate $250,000? A:H...  \n",
              "            A famous building in New York City is turning 1...  [Q:When did Grand Central Terminal first open?...  \n",
              "            Writing articles about films for The Front Page...  [Q:Who did they meet? A:editing for the front ...  \n",
              "4 wikipedia Since 1901, the Nobel Prize in Literature () ha...  [Q:What is the most esteemed award for writing...  \n",
              "            Las Vegas (, Spanish for \"The Meadows\"), offici...  [Q:What does the city advertise itself as? A:T...  \n",
              "            Bath ( or ) is the largest city in the ceremoni...  [Q:Is there a church there? A:yes P:yes, Q:Wha...  \n",
              "            A gene is a locus (or region) of DNA that encod...  [Q:do genes evolve? A:Yes P:yes, Q:what are po...  \n",
              "            A National Olympic Committee (NOC) is a nationa...  [Q:How many NOCs were there in 2016? A:206 P:t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8f584ac-1fff-49ea-b33a-fb6f23659065\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>dialogue</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">cnn</th>\n",
              "      <th>Asuncion, Paraguay (CNN) -- Paraguay installed new top military commanders, but President Fernando Lugo, who had ordered the change in leadership, was not present for the ceremony. \\n\\nLugo's absence Thursday morning attracted attention given his administration's silence on the sudden change in the leadership of the country's army, air force and navy. \\n\\nThe president's decision to replace the top brass came a day after he publicly dismissed rumors about a military coup. \\n\\nBrig. Gen. Bartolome Ramon Pineda Ortiz was named as the new army commander. Brig. Gen. Hugo Gilberto Aranda Chamorro and Rear Adm. Egberto Emerito Orie Benegas took over the top posts at the air force and navy, respectively. \\n\\nThe announcement came from the armed forces, not the president's office. \\n\\nCibar Benitez, commander of the armed forces, was the only top leader to retain his post. \\n\\nOther changes would be forthcoming in the lower ranks, said Benitez at the swearing-in ceremony, but he denied there was any truth to talk of a coup. \\n\\nParaguay's history is filled with unstable transitions of power since it emerged from dictatorship in 1989. Although there hasn't been a coup since that year, there were attempted coups in 1996 and 2000, and President Raul Cubas resigned amid controversy in 1999. \\n\\nThe military shakeup is the third since Lugo took office. The former Catholic bishop was elected to a five-year term last year. His victory brought an end to six decades of one-party rule in Paraguay, but the honeymoon did not last long. \\n\\nIn April, Lugo admitted that he fathered a child while he was still a priest and that he may have fathered more. The revelation, which came as a shock to most, hurt his political image. Calls for his resignation began, and have continued as Lugo has struggled to push reforms through a majority-opposition legislature.</th>\n",
              "      <td>41.250000</td>\n",
              "      <td>[Q:who made the announcement, the office of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CNN) -- A high-speed car accident in Florida has left the teenage son of wrestling star Hulk Hogan seriously injured and a companion in critical condition late Sunday, police said. \\n\\nTV footage shows a person injured in Nick Hogan's car crash being treated in an ambulance. \\n\\nNick Bollea, 17, was the driver of a Toyota Supra that went out of control while driving at a \"high rate of speed\" about 7:30 p.m. Sunday, said Wayne Shelor, a spokesman for the Clearwater police in Clearwater, Florida. \\n\\nThe car \"inexplicably left the roadway,\" jumped across a raised median and slammed into a palm tree just east of downtown, Shelor said. \\n\\n\"It destroyed the car,\" he said. \\n\\nFirefighters had to extract Bollea and his passenger, whose identity was not immediately released, from the wreckage. Both were flown to a hospital in nearby St. Petersburg, Florida, Shelor said. \\n\\n\"They're both down there. Nick's father is down there,\" he said. Watch Hulk Hogan on the scene with the mangled car  \\n\\nHulk Hogan, one of the top professional wrestlers of the 1980s and 1990s, is now featured in the VH1 reality show \"Hogan Knows Best.\" His son, wife Linda and daughter Brooke regularly appear on the show. \\n\\nOne episode documented the son's interest in a type of high-speed car racing known as \"drifting.\" \\n\\nShelor said there was no evidence of drag racing or \"drifting\" in Sunday's wreck. \\n\\nPolice said Bollea -- known to viewers as \"Nick Hogan\" -- was not as seriously hurt as his passenger, who was listed as critical.</th>\n",
              "      <td>36.000000</td>\n",
              "      <td>[Q:Where did this accident occur? A:Florida P:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CNN) -- The United States is deeply concerned about the well-being of Eman al-Obeidy, according to a State Department source, and worked closely with officials in Europe and Libya to get her safely out of the country. The same source said the U.S. is \"prepared to provide whatever help and support Eman may need.\" \\n\\nAl-Obeidy grabbed the world's attention this spring when she accused Libyan leader Moammar Gadhafi's security forces of gang-raping her. \\n\\nShe is now on the way to Malta with her father, according to another high-level U.S. State Department source. She will eventually head to a processing center in Europe before leaving for a final destination. \\n\\nShe has told CNN on repeated occasions that she wants to go to the United States. \\n\\nOne of the State Department sources told CNN that Secretary of State Hillary Clinton \"has been deeply interested in the case and has followed it throughout.\" \\n\\nAl-Obeidy was in Qatar awaiting resettlement as a refugee when she was deported Thursday and sent back to Libya. She was reportedly beaten before being deported. \\n\\nNajah Dawaji, a U.S.-based Libyan pro-freedom activist, said she was with three key members of Libya's Transitional National Council when they first learned that al-Obeidy was forced from Doha and arrived in Benghazi, Libya, on Thursday. She said al-Obeidy had a black eye, bruises on her legs and scratches on her arms. \\n\\nAl-Obeidy told a journalist that officials in the Transitional National Council had pressured the Qataris to expel her. But, according to Dawaji, she did not blame the rebel group for the beating itself.</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>[Q:Who was reportedly beaten before being depo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NEW YORK (CNN) -- Natasha Richardson, a film star, Tony-winning stage actress and member of the famed Redgrave acting family, died Wednesday after suffering injuries in a ski accident, according to a family statement. She was 45. \\n\\nNatasha Richardson fell on a beginners' slope in Canada. \\n\\nRichardson, wife of actor Liam Neeson, was injured Monday in a fall on a ski slope at a Quebec resort about 80 miles northwest of Montreal. \\n\\nRichardson's family released a statement saying, \"Liam Neeson, his sons, and the entire family are shocked and devastated by the tragic death of their beloved Natasha. They are profoundly grateful for the support, love and prayers of everyone, and ask for privacy during this very difficult time.\" \\n\\nAccording to a statement from Mont Tremblant Ski Resort, Richardson fell during a lesson on a beginners' trail. Watch a report on Richardson's life  \\n\\n\"She did not show any visible sign of injury, but the ski patrol followed strict procedures and brought her back to the bottom of the slope and insisted she should see a doctor,\" the statement said. \\n\\nRichardson, accompanied by her instructor, returned to her hotel, but about an hour after the fall was \"not feeling good,\" the statement said. An ambulance was called, and Richardson was taken to a local hospital before being transferred to Hopital du Sacre-Coeur in Montreal. From there she was transferred to Lenox Hill Hospital in New York City. \\n\\nFriends and colleagues were saddened by her death. \\n\\n\"Natasha was brilliant, beautiful, funny, talented beyond measure, as emotionally raw as she was razor sharp,\" said Jodie Foster, who worked with Richardson in \"Nell,\" in a statement. \"Tasha loved fiercely and that love continues in all of us who knew her. May Liam, her beautiful boys and her loving family hold her close as they move through this tragic moment.\"</th>\n",
              "      <td>33.869048</td>\n",
              "      <td>[Q:How did Natasha die? A:She  fell on a begin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paris (CNN) -- French officials Tuesday condemned an Israeli airstrike on Gaza that wounded its consul, his wife and their daughter, calling on Israel to avoid civilian casualties. \\n\\n\"France strongly deplores the consequences of this air strike,\" a statement from the Ministry of Foreign Affairs in Paris announced. \"While France is committed to security in Israel, it reaffirms the imperative need to avoid attacks on civilians. This imperative was reaffirmed to the Israeli authorities.\" \\n\\nThe consul, Majdi Shakoura, was at home with his family in the northern end of Gaza when the airstrike hit about 200 meters (650 feet) away, the Foreign Ministry said. The strike blew out their windows, and they were struck by shards of flying glass, the ministry said. \\n\\nCapt. Aryeh Shalikar, an Israeli military spokesman, told CNN the airstrike was aimed at Palestinian militants who fired a rocket into southern Israel late Sunday. Shalikar said the Israel Defense Forces \"never received any official statement from any source\" regarding injuries to Shakoura or his relatives. \\n\\n\"The IDF wishes to convey that missiles are being fired at Israeli civilians from terrorists, and it has no intention of harming civilians when it returns fire at terrorists,\" he said. \\n\\nPalestinian security and medical officials said one person died and several others were wounded in the airstrike, which they said struck a Hamas naval building in northern Gaza. A Hamas security official said two Israeli rockets struck the building. \\n\\nFrance has a consulate and a cultural center in Gaza \"to support the population,\" the Foreign Ministry said. France has helped build water and sewer systems and rebuild hospitals in Gaza, which is ruled by the Islamic movement Hamas.</th>\n",
              "      <td>32.000000</td>\n",
              "      <td>[Q:Which official condemned the airstrike? A:F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">gutenberg</th>\n",
              "      <th>CHAPTER XX THE FRIEND \\n\\n\\n\\nLess than half an hour later, Marguerite, buried in thoughts, sat inside her coach, which was bearing her swiftly to London. \\n\\nShe had taken an affectionate farewell of little Suzanne, and seen the child safely started with her maid, and in her own coach, back to town. She had sent one courier with a respectful letter of excuse to His Royal Highness, begging for a postponement of the august visit on account of pressing and urgent business, and another on ahead to bespeak a fresh relay of horses at Faversham. \\n\\nThen she had changed her muslin frock for a dark traveling costume and mantle, had provided herself with money--which her husband's lavishness always placed fully at her disposal--and had started on her way. \\n\\nShe did not attempt to delude herself with any vain and futile hopes; the safety of her brother Armand was to have been conditional on the imminent capture of the Scarlet Pimpernel. As Chauvelin had sent her back Armand's compromising letter, there was no doubt that he was quite satisfied in his own mind that Percy Blakeney was the man whose death he had sworn to bring about. \\n\\nNo! there was no room for any fond delusions! Percy, the husband whom she loved with all the ardour which her admiration for his bravery had kindled, was in immediate, deadly peril, through her hand. She had betrayed him to his enemy--unwittingly 'tis true--but she HAD betrayed him, and if Chauvelin succeeded in trapping him, who so far was unaware of his danger, then his death would be at her door. His death! when with her very heart's blood, she would have defended him and given willingly her life for his.</th>\n",
              "      <td>42.857143</td>\n",
              "      <td>[Q:Where was Marguerite? A:inside her coach P:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chapter 17: The Battle Of Moncontor. \\n\\nWhen Pierre left him in order to look after the horses, Philip continued his meal. There could be no hurry, for Nevers was twelve miles away; and it would be four hours, at least, before a party could arrive. \\n\\nThe landlady herself brought in the next course. After placing the dish upon the table, she stood looking earnestly at him for a minute, and then said: \\n\\n\"You spoke of stopping here tonight, sir. The accommodation is very poor and, if you will take my advice, you will ride farther. There have been some men along here this afternoon, inquiring for a party like yours; and offering a reward to any who would carry the news to them, should you pass through. Methinks their intentions were not friendly.\" \\n\\n\"I thank you very much for your counsel,\" Philip said, \"and will take it. I know that there are some who would gladly hinder me, in my journey; and if there is, as you say, a risk of their coming here for me, it were as well that I rode farther, although I would gladly have given my horses a night's rest. I thank you warmly for having warned me.\" \\n\\n\"Do not let my husband know that I have spoken to you,\" she said. \"He is an honest man, but timid; and in these days 'tis safest not to meddle with what does not concern one.\" \\n\\nPhilip waited for two hours, and then told Pierre to saddle the horses, and tell the landlord that he wished to speak to him.</th>\n",
              "      <td>42.000000</td>\n",
              "      <td>[Q:Who was eating? A:Philip P:the king, Q:Did ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER VII \\n\\nThe Beginning of Troubles \\n\\nLily, as she parted with her lover in the garden, had required of him to attend upon her the next morning as he went to his shooting, and in obedience to this command he appeared on Mrs Dale's lawn after breakfast, accompanied by Bernard and two dogs. The men had guns in their hands, and were got up with all proper sporting appurtenances, but it so turned out that they did not reach the stubble-fields on the farther side of the road until after luncheon. And may it not be fairly doubted whether croquet is not as good as shooting when a man is in love? \\n\\nIt will be said that Bernard Dale was not in love; but they who bring such accusation against him, will bring it falsely. He was in love with his cousin Bell according to his manner and fashion. It was not his nature to love Bell as John Eames loved Lily; but then neither would his nature bring him into such a trouble as that which the charms of Amelia Roper had brought upon the poor clerk from the Income-tax Office. Johnny was susceptible, as the word goes; whereas Captain Dale was a man who had his feelings well under control. He was not one to make a fool of himself about a girl, or to die of a broken heart; but, nevertheless, he would probably love his wife when he got a wife, and would be a careful father to his children.</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>[Q:Would people claim bernard wasn't in love? ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER XIV \\n\\nTHE CURE \\n\\nIt was noon when Harding returned to camp, ragged and exhausted, with Clarke limping after him in an even more pitiable state. The latter had suffered badly from the hurried march, but his conductor would brook no delay and the grim hints he had been given encouraged him to the utmost exertion he was capable of. Blake was alive, but when Harding bent over him he feared that help had come too late. His skin looked harsh and dry, his face had grown hollow, and his thick strong hair had turned lank and was falling out. His eyes were vacant and unrecognizing when he turned them upon Harding. \\n\\n\"Here's your patient,\" the American said to Clarke. \"We expect you to cure him, and you had better get to work at once.\" Then his face grew troubled as he asked Benson: \"How long has he been like that?\" \\n\\n\"The last two days,\" said Benson. \"I'm afraid he's very bad.\" \\n\\nHarding sat down with a smothered groan. Every muscle seemed to ache, he could scarcely hold himself upright, and his heart was heavy. He would miss Blake terribly; it was hard to think of going on without him, but he feared that this was inevitable. He was filled with a deep pity for the helpless man, but after a few moments his weary face grew stern. He had done all that he was able, and now Clarke, whom he believed to be a man of high medical skill, must do his part. If he were unsuccessful, it would be the worse for him.</th>\n",
              "      <td>33.684211</td>\n",
              "      <td>[Q:Is it about a disease? A:Yes P:yes, Q:What ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER LXIV. \\n\\n\"Questa montagna e tale, Che sempre al cominciar di sotto a grave. E quanto uom piu va su e men fa male.\" --DANTE: _Il Purgatorio_. \\n\\nIt was not many days after her mother's arrival that Gwendolen would consent to remain at Genoa. Her desire to get away from that gem of the sea, helped to rally her strength and courage. For what place, though it were the flowery vale of Enna, may not the inward sense turn into a circle of punishment where the flowers are no better than a crop of flame-tongues burning the soles of our feet? \\n\\n\"I shall never like to see the Mediterranean again,\" said Gwendolen, to her mother, who thought that she quite understood her child's feeling--even in her tacit prohibition of any express reference to her late husband. \\n\\nMrs. Davilow, indeed, though compelled formally to regard this time as one of severe calamity, was virtually enjoying her life more than she had ever done since her daughter's marriage. It seemed that her darling was brought back to her not merely with all the old affection, but with a conscious cherishing of her mother's nearness, such as we give to a possession that we have been on the brink of losing. \\n\\n\"Are you there, mamma?\" cried Gwendolen, in the middle of the night (a bed had been made for her mother in the same room with hers), very much as she would have done in her early girlhood, if she had felt frightened in lying awake.</th>\n",
              "      <td>31.790123</td>\n",
              "      <td>[Q:Who cries out? A:Gwendolen P:her husband, Q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">mctest</th>\n",
              "      <th>Jessica went to sit in her rocking chair. Today was her birthday and she was turning 80. Her granddaughter Annie was coming over in the afternoon and Jessica was very excited to see her. Her daughter Melanie and Melanie's husband Josh were coming as well. Jessica had a lot to do before they got here, but she was very tired. After taking a nap for half an hour Jessica got up and walked to the drier. She moved the dry clothes into a basket. Next, she took the clothes out of the washer and put them into the drier. She pressed the button on the drier to get it started then walked back out of the room. She also needed to feed her duck. The chickens in her backyard did not need to be fed as they belonged to her neighbor. Jack the dog had been fed earlier that morning and Becky the cat always had food in her bowl. After Jessica finished feeding the duck she came inside and heard the telephone ringing. She answered the phone to hear Annie's excited voice say \"Happy birthday grandma!\" Annie said they would be over very soon. Jessica smiled because she loved her family more than anything. She was very excited. She sat back on her rocking chair and waited until her family arrived.</th>\n",
              "      <td>47.991071</td>\n",
              "      <td>[Q:How old would she be? A:80 P:three, Q:Did s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Greta ran to the corner with her older brother Tony. He had money for the ice cream truck in his pocket and she was very happy. The ice cream truck had been parked at the curb waiting for children for a very long time. The ice cream truck driver thought that no more children were coming to get ice cream so he started pulling away from the curb when they got to the corner. They yelled. They screamed, \"Stop! Stop!\" and jumped up and down on the side walk trying to get him to see them. The driver of the truck saw them, waved at them and smiled, pulled back to the curb and opened his truck up so that they could see everything that he had for sale. They were so excited. They saw some new treats. Tony wanted to try something new. He got an ice cream sundae with chocolate ice cream and nuts. He almost got a snow cone. Greta looked at everything that the ice cream truck had. She saw candy, ice cream cones, snow cones, and everything else. It all looked so good. But after looking at everything, she wanted to get an ice cream sandwich. She got the ice cream sandwich. She bit into it and smiled. It tasted so good. She felt so happy. Her brother, Tony, was happy too. He bit into his ice cream cone sundae and grinned. They walked home with their ice cream and told their mom about how close they came to not getting their ice cream at all. Their mom was happy that the truck had stopped for them. She said that they were very lucky to have gotten to the curb before the ice cream truck left.</th>\n",
              "      <td>45.454545</td>\n",
              "      <td>[Q:Did the ice cream truck start to leave? A:Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jamie and his friends love playing baseball. They play in the park every morning. One summer morning they lost the baseball. Jamie and his friend Joe went to the store. They bought two baseballs. They also bought colas for the other kids. They spent ten dollars. Jamie and Joe went back to the park. His friend Mike drank his cola and went to bat. Mike hit a home run and rounded the bases. All of Jamie's friends cheered very loudly. The sun was very bright and Jamie had an idea. Jamie and his friends went to the pool in town and swam that afternoon. They met Sally and Jessica at the pool. They also met Jenny at the pool. The lifeguard made them put their sandals, watches and hats by the fence. Jamie went home after swimming. He was very tired. He went to sleep but had a lot of fun that day.</th>\n",
              "      <td>42.857143</td>\n",
              "      <td>[Q:where does Jamie play every morning? A:the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Julia gets an allowance from her parents every week for different chores she does every day. The big chore she must do is to feed the dog after school. Julia had a busy day at school and had many tests to complete. When she got home, she forgot to feed her dog, Buddy. Her parents had to feed the dog later. The next day, she forgot again. She saw her parents were feeding Buddy for her each night that she forgot to do it. Julia stopped doing her chore because she knew her parents would take care of it for her. Julia used her extra time to play every day after school. At the end of the week, Julia was excited. She had been wanting a new doll that had come out in the stores. Her friends all had them, and she wanted one, too. But at the end of the week, Julia didn't get an allowance. Her parents told her it was because she had not done her big chore all week, and had played instead. Julia did not get the toy she wanted that week.</th>\n",
              "      <td>40.909091</td>\n",
              "      <td>[Q:did ultimately Julia get her toy A:no P:yes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>On a snowy winter morning, the brown-haired lady saw a squirrel that was hurt. It only had three legs, and it looked hungry. She put some corn out for the squirrel to eat, but other bully squirrels came, too. The brown-haired lady started giving the little squirrel peanuts to eat. She gave some to the bully squirrels, too, so they would leave the three-legged squirrel alone. \\n\\nThe winter snow melted and then it was spring. The grass turned green and the air was warm. Now, when the little squirrel with three legs would come to see the brown-haired lady with the peanuts, it would take the peanuts and dig a little hole and hide the peanuts for later. The squirrel would hold the peanut in its mouth and dig and dig and dig, and then it would put the peanut in the hole and pat it down with its little front paw. Then it would run back over to the brown-haired lady and get some more peanuts to eat.</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>[Q:Who seen a squirrel? A:the lady P:the dog, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">race</th>\n",
              "      <th>\"Everything happens for the best,\" my mother said whenever I was disappointed. \"If you go on, one day something good will happen.\" When I graduated from college, I decided to try for a job in a radio station and then work hard to become a sports announcer . I took a taxi to Chicago and knocked on the door of every station, but I was t _ every time because I didn't have any working experience. Then, I went back home. My father said Montgomery Ward wanted a sports-man to help them. I applied , but I didn't get the job, either. I was very disappointed.\"Everything happens for the best,\" Mom reminded me. Dad let me drive his car to look for jobs. I tried WOC Radio in Davenport, Iowa. The program director, Peter MacArthur, told me they had already had an announcer. His words made me disappointed again. After leaving his office, I was waiting for the elevator when I heard MacArthur calling after me, \"What did you say about sports? Do you know anything about football?\" Then he asked me to broadcast an imaginary game. I did so and Peter told me that I would be broadcasting Saturday's game! On my way home, I thought of my mother's words again:\"If you go on, one day something good will happen.\"</th>\n",
              "      <td>48.684211</td>\n",
              "      <td>[Q:Is the narrator of the story known? A:no P:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ChiChi weighs only 13 pounds. \"He's so tiny,I can carry him with one hand,\" says Mary Lane.\"Most people see him and think he's useless.\" \\n\\nBut last October,ChiChi proved to be more than just a pretty face. Mary and her husband,Rick,were relaxing on the beach one afternoon while on vacation in North Carolina's Outer Banks.As usual,ChiChi was lying on his blanket in his own little beach chair. \\n\\n\"We had our noses buried in books,\"recalls Rick,\"when suddenly the dog became extremely uneasy. His bark was different from anything we had heard before.And he would not let us ignore him.\" \\n\\nChiChi ran back and forth in front of his chair as if to run down the beach.The Lanes sat up to see two elderly women in the ocean,about 100 yards down the beach and 10 feet off shore.One was on her back,her head under the waves.The other was struggling hard to keep her friend's head above the surface. \\n\\nThe Lanes rushed across the sand and into the surf. Rick went to the woman in danger of drowning,while Mary held fast on to the other one and pulled her up on the beach.\"Then I went back to help Rick,\" Mary says.\"The sand dropped off steeply,and a riptide was beating the woman under. She was completely helpless.\" \\n\\nNot getting well from recent knee surgery,the woman had been unable to turn over or push herself up.\"Her friend had been in danger too,\" Mary says.\"The waves were pushing her around. There's no way she could have held on much longer.\" \\n\\nThe women hadn't called out for help. \"They were struggling so hard that there was no time for screaming,\" Mary recalls.\"But ChiChi had sensed their danger.\" \\n\\nDuty done,ChiChi was back in his chair,asleep,by the time the two women were on dry ground and the Lanes had returned to their blankets.Luckily,the women were fine,though shaken.They thanked the Lanes for saving their lives. \\n\\nBack home in Greensboro,North Carolina,the Lanes ordered a special collar with the words \"Hero Dog\" on it.</th>\n",
              "      <td>43.609023</td>\n",
              "      <td>[Q:Is ChiChi a person? A:no P:yes, Q:What is h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GERALD Christian is in Grade 8 at Ridge Road Middle School in North Carolina, US. She is a member of her school basketball team. Late last month, the 14-year-old faced a big problem. Her mother lost her job. She thought she couldn't pay the $ 50 fee for the city's sports meet this year. Christian was not the only one who had this problem. Some other middle school players in the city had the same problem. That's why famous NBA player Michael Jordan gave $ 250, 000 to the city earlier this month. He wanted to help the poor students. Jordan said: \"I know there are kids who get an education by playing sports. We need to keep sports alive for them.\" Christian was _ . \"Really? I can't believe Michael did that for us. These days, I go to bed thinking about it and I wake up thinking about it,\" she said. \"Now the problem is over. \" Christian wanted to say \"thanks\" to Jordan. \"Michael, thank you for giving me the chance to show myself. I will do my best at the meet.</th>\n",
              "      <td>43.518519</td>\n",
              "      <td>[Q:why did michael jordan donate $250,000? A:H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A famous building in New York City is turning 100 years old. A year-long celebration is planned for Grand Central Terminal, which is usually called Grand Central station, the sixth most-visited place in the world. The huge building has not changed much since it opened in February, 1913. About 750,000 people pass through Grand Central every day. Some just come to look at it, others to visit the stores. But most are there to catch the trains that enter and leave from the station. It is the largest train station in the world. There are 67 train tracks, all of them underground. The main part of the building has large, arched windows, a jeweled four-sided clock and ticket windows. Grand Central has been seen in many movies through the years. Dan Brucker is with the New York Transit Authority, which operates the station. Dan Brucker has worked for the transit authority at Grand Central for 30 years. In all those years, he has not lost his interest in the building. Justin Ferate, a historian, has been giving tours of Grand Central Station for 30 years. He says the station was designed to make travel a pleasure. \"Why people don't run into each other in Grand Central is simple: each block of stone in Grand Central is the length of your leg. Each block of stone in Grand Central is the length of your arm. Each block of stone is a different color, so it's a checkerboard, based on you.\" A ten-year-long fight against plans to build a huge office building over Grand Central in 1968 helped create the modern preservation movement. Now, no one would think of changing the beauty of the station.</th>\n",
              "      <td>36.224490</td>\n",
              "      <td>[Q:When did Grand Central Terminal first open?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Writing articles about films for The Front Page was my first proper job. Before then I had done bits of reviewing--novels for other newspapers, films for a magazine and anything I was asked to do for the radio. That was how I met Tom Seaton, the first arts editor of The Front Page, who had also written for television. He hired me, but Tom was not primarily a journalist, or he would certainly have been more careful in choosing his staff. \\n\\nAt first, his idea was that a team of critics should take care of the art forms that didn't require specialized knowledge: books, TV, theatre, film and radio. There would be a weekly lunch at which we would make our choices from the artistic material that Tom had decided we should cover, though there would also be guests to make the atmosphere sociable. \\n\\nIt all felt like a bit of dream at that time: a new newspaper and I was one of the team. It seemed so unlikely that a paper could be introduced into a crowded market. It seemed just as likely that a millionaire wanted to help me personally, and was pretending to employ me. Such was my lack of self-confidence. \\n\\nTom's original scheme for a team of critics for the arts never took off. It was a good idea, but we didn't get together as planned and so everything was done by phone. It turned out, too, that the general public out there preferred to associate a reviewer with a single subject area, and so I chose film. Without Tom's initial push, though, we would hardly have come up with the present arrangement, by which I write an extended weekly piece, usually on one film. \\n\\nThe space I am given allows me to broaden my argument--or forces me, in an uninteresting week, to make something out of nothing. But what is my role in the public arena? I assume that people choose what films to go to on the basis of the stars, the publicity or the director. So if a film review isn't really a consumer guide, what is it? I certainly don't feel I have a responsibility to be 'right' about a movie. Nor do I think there should be a certain number of 'great' and 'bad' films each year. All I have to do is put forward an argument. I'm not a judge, and nor would I want to be.</th>\n",
              "      <td>35.802469</td>\n",
              "      <td>[Q:Who did they meet? A:editing for the front ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">wikipedia</th>\n",
              "      <th>Since 1901, the Nobel Prize in Literature () has been awarded annually to an author from any country who has, in the words of the will of Alfred Nobel, produced \"in the field of literature the most outstanding work in an ideal direction\" (original Swedish: \"den som inom litteraturen har producerat det mest framstende verket i en idealisk riktning\"). Though individual works are sometimes cited as being particularly noteworthy, here \"work\" refers to an author's work as a whole. The Swedish Academy decides who, if anyone, will receive the prize in any given year. The academy announces the name of the chosen laureate in early October. It is one of the five Nobel Prizes established by the will of Alfred Nobel in 1895; the others are the Nobel Prize in Chemistry, Nobel Prize in Physics, Nobel Peace Prize, and Nobel Prize in Physiology or Medicine. \\n\\nAlthough the Nobel Prize in Literature has become the world's most prestigious literature prize, the Swedish Academy has attracted significant criticism for its handling of the award. Many authors who have won the prize have fallen into obscurity, while others rejected by the jury remain widely studied and read, like Ruben Daro. The prize has \"become widely seen as a political one - a peace prize in literary disguise\", whose judges are prejudiced against authors with different political tastes to them. Tim Parks has expressed skepticism that it is possible for \"Swedish professors ... [to] compar[e] a poet from Indonesia, perhaps translated into English with a novelist from Cameroon, perhaps available only in French, and another who writes in Afrikaans but is published in German and Dutch...\". As of 2016, 16 of the 113 recipients have been of Scandinavian origin. The Academy has often been alleged to be biased towards European, and in particular Swedish, authors. Some, such as Indian academic Sabaree Mitra, have noted that, though the Nobel Prize in Literature is significant and tends to overshadow other awards, it is \"not the only benchmark of literary excellence.\"</th>\n",
              "      <td>42.907268</td>\n",
              "      <td>[Q:What is the most esteemed award for writing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Las Vegas (, Spanish for \"The Meadows\"), officially the City of Las Vegas and often known simply as Vegas, is the 28th-most populated city in the United States, the most populated city in the state of Nevada, and the county seat of Clark County. The city anchors the Las Vegas Valley metropolitan area and is the largest city within the greater Mojave Desert. Las Vegas is an internationally renowned major resort city, known primarily for its gambling, shopping, fine dining, entertainment, and nightlife. The Las Vegas Valley as a whole serves as the leading financial, commercial, and cultural center for Nevada. \\n\\nThe city bills itself as The Entertainment Capital of the World, and is famous for its mega casinohotels and associated activities. It is a top three destination in the United States for business conventions and a global leader in the hospitality industry, claiming more AAA Five Diamond hotels than any other city in the world. Today, Las Vegas annually ranks as one of the world's most visited tourist destinations. The city's tolerance for numerous forms of adult entertainment earned it the title of Sin City, and has made Las Vegas a popular setting for literature, films, television programs, and music videos.</th>\n",
              "      <td>36.363636</td>\n",
              "      <td>[Q:What does the city advertise itself as? A:T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bath ( or ) is the largest city in the ceremonial county of Somerset, England, known for its Roman-built baths. In 2011, the population was 88,859. Bath is in the valley of the River Avon, west of London and south-east of Bristol. The city became a World Heritage Site in 1987. \\n\\nThe city became a spa with the Latin name \" (\"the waters of Sulis\") AD60 when the Romans built baths and a temple in the valley of the River Avon, although hot springs were known even before then. \\n\\nBath Abbey was founded in the 7th century and became a religious centre; the building was rebuilt in the 12th and 16th centuries. In the 17th century, claims were made for the curative properties of water from the springs, and Bath became popular as a spa town in the Georgian era. Georgian architecture, crafted from Bath stone, includes the Royal Crescent, Circus, Pump Room, and Assembly Rooms where Beau Nash presided over the city's social life from 1705 until his death in 1761. Many of the streets and squares were laid out by John Wood, the Elder, and in the 18th century the city became fashionable and the population grew. Jane Austen lived in Bath in the early 19th century. Further building was undertaken in the 19th century and following the Bath Blitz in World War II.</th>\n",
              "      <td>36.134454</td>\n",
              "      <td>[Q:Is there a church there? A:yes P:yes, Q:Wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A gene is a locus (or region) of DNA that encodes a functional RNA or protein product, and is the molecular unit of heredity.:Glossary The transmission of genes to an organism's offspring is the basis of the inheritance of phenotypic traits. Most biological traits are under the influence of polygenes (many different genes) as well as the geneenvironment interactions. Some genetic traits are instantly visible, such as eye colour or number of limbs, and some are not, such as blood type, risk for specific diseases, or the thousands of basic biochemical processes that comprise life. \\n\\nGenes can acquire mutations in their sequence, leading to different variants, known as alleles, in the population. These alleles encode slightly different versions of a protein, which cause different phenotype traits. Colloquial usage of the term \"having a gene\" (e.g., \"good genes,\" \"hair colour gene\") typically refers to having a different allele of the gene. Genes evolve due to natural selection or survival of the fittest of the alleles.</th>\n",
              "      <td>33.333333</td>\n",
              "      <td>[Q:do genes evolve? A:Yes P:yes, Q:what are po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A National Olympic Committee (NOC) is a national constituent of the worldwide Olympic movement. Subject to the controls of the International Olympic Committee, NOCs are responsible for organizing their people's participation in the Olympic Games. They may nominate cities within their respective areas as candidates for future Olympic Games. NOCs also promote the development of athletes and training of coaches and officials at a national level within their geographies. \\n\\nAs of 2016, there are 206 NOCs: Each of the 193 member states of the United Nations; United Nations observer state Palestine; the Cook Islands, a state in free association with New Zealand whose capacity to participate in international organizations has been recognized by the United Nations Secretariat; and two states with limited recognition, Kosovo and Taiwan (designated as \"Chinese Taipei\" by the IOC). \\n\\nThere are also nine dependent territories with NOCs: \\n\\nPrior to 1996, rules for recognising separate countries within the IOC were not as strict as those within the United Nations, which allowed these territories to field teams separately from their sovereign state. Following an amendment to the Olympic Charter in 1996, NOC recognition can only be granted after recognition as an independent state by the international community. Since the rule does not apply retroactively, the dependent territories which were recognised before the rule change are allowed to continue sending separate teams to the Olympics, while the Faroe Islands and Macau send their own Paralympic teams.</th>\n",
              "      <td>29.411765</td>\n",
              "      <td>[Q:How many NOCs were there in 2016? A:206 P:t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8f584ac-1fff-49ea-b33a-fb6f23659065')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8f584ac-1fff-49ea-b33a-fb6f23659065 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8f584ac-1fff-49ea-b33a-fb6f23659065');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1814004",
      "metadata": {
        "id": "f1814004"
      },
      "source": [
        "# Assignment Evaluation\n",
        "\n",
        "The following assignment points will be awarded for each task as follows:\n",
        "\n",
        "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
        "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
        "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
        "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
        "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
        "* Report $\\rightarrow$ 1.0 points.\n",
        "\n",
        "**Total** = 6 points <br>\n",
        "\n",
        "We may award an additional 0.5 points for outstanding submissions. \n",
        " \n",
        "**Speed Bonus** = 0.5 extra points <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a1b2b9",
      "metadata": {
        "id": "20a1b2b9"
      },
      "source": [
        "## Report\n",
        "\n",
        "We apply the rules described in Assignment 1 regarding the report.\n",
        "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
        "* Report validation and test results in a table.$^1$\n",
        "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0967c209",
      "metadata": {
        "id": "0967c209"
      },
      "source": [
        "## Comments and Organization\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
        "\n",
        "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
        "\n",
        "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23929660",
      "metadata": {
        "id": "23929660"
      },
      "source": [
        "## FAQ (READ THIS!)\n",
        "\n",
        "---\n",
        "\n",
        "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
        "\n",
        "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_text = tokenizer(text)\n",
        "%% Alternatively\n",
        "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
        "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "```\n",
        "\n",
        "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
        "\n",
        "**Answer**: Here are some common workarounds:\n",
        "\n",
        "1. Try decreasing the mini-batch size\n",
        "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c56a612",
      "metadata": {
        "id": "9c56a612"
      },
      "source": [
        "## Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bac4b9",
      "metadata": {
        "id": "54bac4b9"
      },
      "source": [
        "## The End!\n",
        "\n",
        "Questions?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [
        "dL4rB4Dv4q5D",
        "11ada8c8",
        "66cfee64",
        "7b532042",
        "f6643e14",
        "bddb1b09",
        "icicV7K0sEzm",
        "C4RB6BoVsmgO",
        "pGrX37BsSQaM",
        "b8EXn3NrYo6D",
        "f60g6Nu2z8QE",
        "Q7FiFQD0Yv-n",
        "5KDoYgi13amI",
        "zP9VsaqkfIhm",
        "AwS-X-YdsiFH",
        "ir9nt1qwbkvb",
        "e2WHzAP0boZV",
        "I3sK03-Ubs-L",
        "-aYGDoUWbxxd",
        "qob7laawl5bN",
        "tS8vj3vkivit",
        "Ju27ZRiJbI_C",
        "ffJy4f8YbYer",
        "9w6fsjOGtG_y",
        "AntOxXv8C44o",
        "f1814004"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('tf_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3ce8273a8c38ff7795926bf915cbd2931d7313de696d3392f6c42417e8c00d4d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e79a4d3f7f9b45a3938bbf3d5fcab56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57c99948d1484714bef0817f885ef9f4",
              "IPY_MODEL_1dbad66ef56b4e1e9a017cba84815635"
            ],
            "layout": "IPY_MODEL_c0400af409b24c039f349070ebafa00b"
          }
        },
        "57c99948d1484714bef0817f885ef9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "bert-tiny/full_history",
              "bert-tiny/full_no_history",
              "distilroberta-base/42_no_history"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "<font size=3>Choose the model to use for the evaluation:</font>",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_6293ac27c02c4d5d9073c77a239db6bd",
            "style": "IPY_MODEL_da866412e23b4c30bf95aeb8b2a5498a"
          }
        },
        "1dbad66ef56b4e1e9a017cba84815635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Confirm model",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3d8e61fefffc4dab98d0fa5437afb404",
            "style": "IPY_MODEL_6936957dc27642c5b6120329dd63804b",
            "tooltip": ""
          }
        },
        "c0400af409b24c039f349070ebafa00b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6293ac27c02c4d5d9073c77a239db6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "40px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "40%"
          }
        },
        "da866412e23b4c30bf95aeb8b2a5498a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "3d8e61fefffc4dab98d0fa5437afb404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6936957dc27642c5b6120329dd63804b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": "600"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}