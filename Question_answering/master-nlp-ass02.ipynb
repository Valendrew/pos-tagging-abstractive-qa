{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d23b6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
    "\n",
    "**Keywords**: Transformers, Question Answering, CoQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ada8c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c07553",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Problem\n",
    "\n",
    "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4907f8d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Task\n",
    "\n",
    "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
    "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
    "\n",
    "**Note**: an question $Q$ can refer to previous dialogue turns. <br>\n",
    "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3760b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Models\n",
    "\n",
    "We are going to experiment with transformer-based models to define the following models:\n",
    "\n",
    "1.  $A = f_\\theta(Q, P)$\n",
    "\n",
    "2. $A = f_\\theta(Q, P, H)$\n",
    "\n",
    "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfee64",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The CoQA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996fa650",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3e7d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6c37e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Rationales\n",
    "\n",
    "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
    "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa786e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dataset Statistics\n",
    "\n",
    "* **127k** QA pairs.\n",
    "* **8k** conversations.\n",
    "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
    "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
    "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
    "* Only **train** and **validation** sets are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d68b7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dataset snippet\n",
    "\n",
    "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"source\": \"mctest\",\n",
    "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
    "    \"filename\": \"mc160.test.41\",\n",
    "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
    "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
    "    \"questions\": [\n",
    "        {\n",
    "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
    "            \"turn_id\": 1\n",
    "        },\n",
    "        {\n",
    "            \"input_text\": \"Where did she live?\",\n",
    "            \"turn_id\": 2\n",
    "        },\n",
    "        [...]\n",
    "    ],\n",
    "    \"answers\": [\n",
    "        {\n",
    "            \"span_start\": 59,   % <-- $R_1$ start index\n",
    "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
    "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
    "            \"input_text\" \"white\",   % <-- $A_1$      \n",
    "            \"turn_id\": 1\n",
    "        },\n",
    "        [...]\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7558c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simplifications\n",
    "\n",
    "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
    "\n",
    "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f96864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import tensorflow.keras.callbacks\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.losses\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b532042",
   "metadata": {},
   "source": [
    "## TASKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01cdad7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Task 1] Remove unaswerable QA pairs - DONE \n",
    "\n",
    "Write your own script to remove unaswerable QA pairs from both train and validation sets. The unanswarable questions have -1 both in 'span_start' and 'span_end' and *unknown* in 'span_text'.      \n",
    "***WARNING***: I found out that the sample in position 8246 has 'unknown' as answer therefore we must use the 'span_start' attribute to check for answerability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57334e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Task 2] Train, Validation and Test splits - DONE\n",
    "\n",
    "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
    "\n",
    "We'll consider the provided validation set as a test set. <br>\n",
    "$\\rightarrow$ Write your own script to:\n",
    "* Split the train data in train and validation splits (80% train and 20% val)\n",
    "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
    "* Perform splitting using the following seed for reproducibility: 42\n",
    "\n",
    "#### Reproducibility Memo\n",
    "\n",
    "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a21de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Task 3] Model definition\n",
    "\n",
    "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
    "\n",
    "* [M1] DistilRoBERTa (distilberta-base)\n",
    "* [M2] BERTTiny (bert-tiny)\n",
    "\n",
    "**Note**: Remember to install the ```transformers``` python package!\n",
    "\n",
    "**Note**: We consider small transformer models for computational reasons!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e83f28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Task 4] Question generation with text passage $P$ and question $Q$\n",
    "\n",
    "We want to define $f_\\theta(P, Q)$. \n",
    "\n",
    "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
    "\n",
    "#### Formulation\n",
    "\n",
    "Consider a dialogue on text passage $P$. \n",
    "\n",
    "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311ba86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
    "\n",
    "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
    "\n",
    "#### Formulation\n",
    "\n",
    "Consider a dialogue on text passage $P$. \n",
    "\n",
    "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac768c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
    "\n",
    "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
    "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
    "* Fine-tune each transformer-based models for **3 epochs**.\n",
    "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
    "\n",
    "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
    "\n",
    "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7e98f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Task 7] Error Analysis\n",
    "\n",
    "Perform a simple and short error analysis as follows:\n",
    "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
    "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
    "\n",
    "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6643e14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358bac70",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def download_data(data_path, url_path, suffix):    \n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "        \n",
    "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
    "        download_url(url=url_path, output_path=data_path)\n",
    "        print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f6ab3ff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
    "\n",
    "# Test data\n",
    "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb1b09",
   "metadata": {},
   "source": [
    "## Create the dataframe and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "89e33d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './coqa/train.json'\n",
    "test_path = './coqa/test.json'\n",
    "\n",
    "with open(train_path, 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "\n",
    "with open(test_path, 'r') as f:\n",
    "    test_json = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9a10f052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>story</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>Vatican_Library.txt</td>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>[{'input_text': 'When was the Vat formally ope...</td>\n",
       "      <td>[{'span_start': 151, 'span_end': 179, 'span_te...</td>\n",
       "      <td>Vatican_Library.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn</td>\n",
       "      <td>3wj1oxy92agboo5nlq4r7bndc3t8a8</td>\n",
       "      <td>cnn_fe05c61a7e48461f7883cdec387567029614f07b.s...</td>\n",
       "      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n",
       "      <td>[{'input_text': 'Where was the Auction held?',...</td>\n",
       "      <td>[{'span_start': 243, 'span_end': 284, 'span_te...</td>\n",
       "      <td>cnn_fe05c61a7e48461f7883cdec387567029614f07b.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gutenberg</td>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>data/gutenberg/txt/Zane Grey___Riders of the P...</td>\n",
       "      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n",
       "      <td>[{'input_text': 'What did Venters call Lassite...</td>\n",
       "      <td>[{'span_start': 841, 'span_end': 880, 'span_te...</td>\n",
       "      <td>data/gutenberg/txt/Zane Grey___Riders of the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn</td>\n",
       "      <td>3ewijtffvo7wwchw6rtyaf7mfwte0p</td>\n",
       "      <td>cnn_0c518067e0df811501e46b2e1cd1ce511f1645b7.s...</td>\n",
       "      <td>(CNN) -- The longest-running holiday special s...</td>\n",
       "      <td>[{'input_text': 'Who is Rudolph's father?', 't...</td>\n",
       "      <td>[{'span_start': 500, 'span_end': 557, 'span_te...</td>\n",
       "      <td>cnn_0c518067e0df811501e46b2e1cd1ce511f1645b7.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gutenberg</td>\n",
       "      <td>3urfvvm165iantk80llvkwwbjs7uzh</td>\n",
       "      <td>data/gutenberg/txt/Rafael Sabatini___Love-at-A...</td>\n",
       "      <td>CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...</td>\n",
       "      <td>[{'input_text': 'Who arrived at the church?', ...</td>\n",
       "      <td>[{'span_start': 254, 'span_end': 297, 'span_te...</td>\n",
       "      <td>data/gutenberg/txt/Rafael Sabatini___Love-at-A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                              id  \\\n",
       "0  wikipedia  3zotghdk5ibi9cex97fepx7jetpso7   \n",
       "1        cnn  3wj1oxy92agboo5nlq4r7bndc3t8a8   \n",
       "2  gutenberg  3bdcf01ogxu7zdn9vlrbf2rqzwplyf   \n",
       "3        cnn  3ewijtffvo7wwchw6rtyaf7mfwte0p   \n",
       "4  gutenberg  3urfvvm165iantk80llvkwwbjs7uzh   \n",
       "\n",
       "                                            filename  \\\n",
       "0                                Vatican_Library.txt   \n",
       "1  cnn_fe05c61a7e48461f7883cdec387567029614f07b.s...   \n",
       "2  data/gutenberg/txt/Zane Grey___Riders of the P...   \n",
       "3  cnn_0c518067e0df811501e46b2e1cd1ce511f1645b7.s...   \n",
       "4  data/gutenberg/txt/Rafael Sabatini___Love-at-A...   \n",
       "\n",
       "                                               story  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  New York (CNN) -- More than 80 Michael Jackson...   \n",
       "2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n",
       "3  (CNN) -- The longest-running holiday special s...   \n",
       "4  CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...   \n",
       "\n",
       "                                           questions  \\\n",
       "0  [{'input_text': 'When was the Vat formally ope...   \n",
       "1  [{'input_text': 'Where was the Auction held?',...   \n",
       "2  [{'input_text': 'What did Venters call Lassite...   \n",
       "3  [{'input_text': 'Who is Rudolph's father?', 't...   \n",
       "4  [{'input_text': 'Who arrived at the church?', ...   \n",
       "\n",
       "                                             answers  \\\n",
       "0  [{'span_start': 151, 'span_end': 179, 'span_te...   \n",
       "1  [{'span_start': 243, 'span_end': 284, 'span_te...   \n",
       "2  [{'span_start': 841, 'span_end': 880, 'span_te...   \n",
       "3  [{'span_start': 500, 'span_end': 557, 'span_te...   \n",
       "4  [{'span_start': 254, 'span_end': 297, 'span_te...   \n",
       "\n",
       "                                                name  \n",
       "0                                Vatican_Library.txt  \n",
       "1  cnn_fe05c61a7e48461f7883cdec387567029614f07b.s...  \n",
       "2  data/gutenberg/txt/Zane Grey___Riders of the P...  \n",
       "3  cnn_0c518067e0df811501e46b2e1cd1ce511f1645b7.s...  \n",
       "4  data/gutenberg/txt/Rafael Sabatini___Love-at-A...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.json_normalize(train_json['data'])\n",
    "df_test = pd.json_normalize(test_json['data'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730969bf",
   "metadata": {},
   "source": [
    "In the dataset above we have some features that are not useful for our task therefore we decided to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "af8558f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = ['source', 'id', 'filename', 'name']\n",
    "features_to_remove_test = features_to_remove + [f'additional_answers.{i}' for i in range(3)]\n",
    "\n",
    "df_train.drop(features_to_remove, axis=1, inplace=True)\n",
    "df_test.drop(features_to_remove_test, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6bce7aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>[{'input_text': 'When was the Vat formally ope...</td>\n",
       "      <td>[{'span_start': 151, 'span_end': 179, 'span_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n",
       "      <td>[{'input_text': 'Where was the Auction held?',...</td>\n",
       "      <td>[{'span_start': 243, 'span_end': 284, 'span_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n",
       "      <td>[{'input_text': 'What did Venters call Lassite...</td>\n",
       "      <td>[{'span_start': 841, 'span_end': 880, 'span_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN) -- The longest-running holiday special s...</td>\n",
       "      <td>[{'input_text': 'Who is Rudolph's father?', 't...</td>\n",
       "      <td>[{'span_start': 500, 'span_end': 557, 'span_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...</td>\n",
       "      <td>[{'input_text': 'Who arrived at the church?', ...</td>\n",
       "      <td>[{'span_start': 254, 'span_end': 297, 'span_te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  New York (CNN) -- More than 80 Michael Jackson...   \n",
       "2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n",
       "3  (CNN) -- The longest-running holiday special s...   \n",
       "4  CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...   \n",
       "\n",
       "                                           questions  \\\n",
       "0  [{'input_text': 'When was the Vat formally ope...   \n",
       "1  [{'input_text': 'Where was the Auction held?',...   \n",
       "2  [{'input_text': 'What did Venters call Lassite...   \n",
       "3  [{'input_text': 'Who is Rudolph's father?', 't...   \n",
       "4  [{'input_text': 'Who arrived at the church?', ...   \n",
       "\n",
       "                                             answers  \n",
       "0  [{'span_start': 151, 'span_end': 179, 'span_te...  \n",
       "1  [{'span_start': 243, 'span_end': 284, 'span_te...  \n",
       "2  [{'span_start': 841, 'span_end': 880, 'span_te...  \n",
       "3  [{'span_start': 500, 'span_end': 557, 'span_te...  \n",
       "4  [{'span_start': 254, 'span_end': 297, 'span_te...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd3b662",
   "metadata": {},
   "source": [
    "At this point we can split the dataset in training and validation and then we separate the story and the questions from the answers for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d7cc3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 42\n",
    "\n",
    "def split_train_validation(df: pd.DataFrame, val_size: float=0.2, \n",
    "    random_state: int=None) -> typing.Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    '''\n",
    "        It takes as input a dataframe and it splits it in 2 dataframes considering the \n",
    "        'val_size' parameter. \n",
    "    '''\n",
    "\n",
    "    validation = df.sample(frac=val_size, random_state=random_state) \n",
    "    training = df.drop(validation.index).sample(frac=1, random_state=random_state)\n",
    "\n",
    "    return training.reset_index(drop=True), validation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a63f6ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the datasets are:\n",
      "Training dataset -> (5759, 3) - Validation dataset -> (1440, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = split_train_validation(df_train, 0.2, rand_seed)\n",
    "print(f\"The dimensions of the datasets are:\\n\"\n",
    "     f\"Training dataset -> {df_train.shape} - Validation dataset -> {df_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "be70ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df: pd.DataFrame, to_drop: typing.List[str]=[]) -> typing.Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    '''\n",
    "        Given a Pandas dataframe this function returns 2 dataframe, the first one\n",
    "        contains the story and the questions (X) and the second one contains the answers (y).\n",
    "    '''\n",
    "    questions = [{'story':df.story[i], **quest} for i, lis in enumerate(df.questions) for quest in lis]\n",
    "    answers = [ans for lis in df.answers for ans in lis]\n",
    "\n",
    "    X = pd.DataFrame.from_dict(questions, orient=\"columns\").drop(to_drop, axis=1)\n",
    "    y = pd.DataFrame.from_dict(answers, orient=\"columns\").drop(to_drop, axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6e6f82ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 86898 samples, the validation set has 21749 samplesand the test set has 7983 samples.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = split_dataset(df_train, to_drop=['turn_id', 'bad_turn'])\n",
    "x_val, y_val = split_dataset(df_val, to_drop=['turn_id', 'bad_turn'])\n",
    "x_test, y_test = split_dataset(df_test, to_drop=['turn_id'])\n",
    "\n",
    "print(f\"The training set has {len(x_train)} samples, the validation set has {len(x_val)} samples\"\n",
    "      f\"and the test set has {len(x_test)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b279bf3",
   "metadata": {},
   "source": [
    "Now we will remove all the unanswerable questions as written in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ee6c8b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have removed:\n",
      "- -3490 unanswerable questions from the training set;\n",
      "- -900 unanswerable questions from the validation set;\n",
      "- -288 unanswerable questions from the test set;\n"
     ]
    }
   ],
   "source": [
    "keep_rows_train = list(y_train.span_start > 0)\n",
    "keep_rows_val = list(y_val.span_start > 0)\n",
    "keep_rows_test = list(y_test.span_start > 0)\n",
    "\n",
    "x_train = x_train.iloc[keep_rows_train].reset_index(drop=True)\n",
    "y_train = y_train.iloc[keep_rows_train].reset_index(drop=True)\n",
    "\n",
    "x_val = x_val.iloc[keep_rows_val].reset_index(drop=True)\n",
    "y_val = y_val.iloc[keep_rows_val].reset_index(drop=True)\n",
    "\n",
    "x_test = x_test.iloc[keep_rows_test].reset_index(drop=True)\n",
    "y_test = y_test.iloc[keep_rows_test].reset_index(drop=True)\n",
    "\n",
    "print(f\"We have removed:\\n- {len(x_train) - len(keep_rows_train)} unanswerable questions from the training set;\\n\"\n",
    "      f\"- {len(x_val) - len(keep_rows_val)} unanswerable questions from the validation set;\\n\"\n",
    "      f\"- {len(x_test) - len(keep_rows_test)} unanswerable questions from the test set;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a3d6ccb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the questions dataset is (83408, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHAPTER 52 \\n\\nNicholas despairs of rescuing M...</td>\n",
       "      <td>Who is losing their nerve?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHAPTER 52 \\n\\nNicholas despairs of rescuing M...</td>\n",
       "      <td>Who is he worried about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHAPTER 52 \\n\\nNicholas despairs of rescuing M...</td>\n",
       "      <td>What is her last name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAPTER 52 \\n\\nNicholas despairs of rescuing M...</td>\n",
       "      <td>Does he get it back?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHAPTER 52 \\n\\nNicholas despairs of rescuing M...</td>\n",
       "      <td>Who is an obstacle for him?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  CHAPTER 52 \\n\\nNicholas despairs of rescuing M...   \n",
       "1  CHAPTER 52 \\n\\nNicholas despairs of rescuing M...   \n",
       "2  CHAPTER 52 \\n\\nNicholas despairs of rescuing M...   \n",
       "3  CHAPTER 52 \\n\\nNicholas despairs of rescuing M...   \n",
       "4  CHAPTER 52 \\n\\nNicholas despairs of rescuing M...   \n",
       "\n",
       "                    input_text  \n",
       "0   Who is losing their nerve?  \n",
       "1     Who is he worried about?  \n",
       "2       What is her last name?  \n",
       "3         Does he get it back?  \n",
       "4  Who is an obstacle for him?  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The shape of the questions dataset is {x_train.shape}\")\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0d90c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the answers dataset is (83408, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span_start</th>\n",
       "      <th>span_end</th>\n",
       "      <th>span_text</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>Nicholas</td>\n",
       "      <td>Nicholas is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>Madeline</td>\n",
       "      <td>Madeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "      <td>Bray</td>\n",
       "      <td>Bray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>plucks up his Spirits again</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190</td>\n",
       "      <td>197</td>\n",
       "      <td>Newman</td>\n",
       "      <td>Newman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   span_start  span_end                    span_text   input_text\n",
       "0          13        22                    Nicholas   Nicholas is\n",
       "1          43        51                     Madeline     Madeline\n",
       "2          52        56                         Bray         Bray\n",
       "3          62        89  plucks up his Spirits again          Yes\n",
       "4         190       197                      Newman        Newman"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The shape of the answers dataset is {y_train.shape}\")\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1814004",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment Evaluation\n",
    "\n",
    "The following assignment points will be awarded for each task as follows:\n",
    "\n",
    "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
    "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
    "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
    "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
    "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
    "* Report $\\rightarrow$ 1.0 points.\n",
    "\n",
    "**Total** = 6 points <br>\n",
    "\n",
    "We may award an additional 0.5 points for outstanding submissions. \n",
    " \n",
    "**Speed Bonus** = 0.5 extra points <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1b2b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Report\n",
    "\n",
    "We apply the rules described in Assignment 1 regarding the report.\n",
    "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
    "* Report validation and test results in a table.$^1$\n",
    "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967c209",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comments and Organization\n",
    "\n",
    "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
    "\n",
    "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
    "\n",
    "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23929660",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FAQ (READ THIS!)\n",
    "\n",
    "---\n",
    "\n",
    "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
    "\n",
    "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
    "\n",
    "**Example**: \n",
    "\n",
    "```\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "encoded_text = tokenizer(text)\n",
    "%% Alternatively\n",
    "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
    "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
    "```\n",
    "\n",
    "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
    "\n",
    "**Answer**: Here are some common workarounds:\n",
    "\n",
    "1. Try decreasing the mini-batch size\n",
    "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56a612",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contact\n",
    "\n",
    "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
    "\n",
    "Teaching Assistants:\n",
    "\n",
    "* Andrea Galassi -> a.galassi@unibo.it\n",
    "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
    "\n",
    "Professor:\n",
    "\n",
    "* Paolo Torroni -> p.torroni@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bac4b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The End!\n",
    "\n",
    "Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ce8273a8c38ff7795926bf915cbd2931d7313de696d3392f6c42417e8c00d4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
